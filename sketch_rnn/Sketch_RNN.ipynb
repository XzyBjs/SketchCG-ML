{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tDybPQiEFQuJ"
   },
   "source": [
    "In this notebook, we will show how to load pre-trained models and draw things with sketch-rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k0GqvYgB9JLC",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-27 19:48:01.347686: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-12-27 19:48:08.253305: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-12-27 19:48:08.253353: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-12-27 19:48:08.634393: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-12-27 19:48:09.117550: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-12-27 19:48:15.969702: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# import the required libraries\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "# import cPickle\n",
    "import codecs\n",
    "import collections\n",
    "import os\n",
    "import math\n",
    "import json\n",
    "import tensorflow as tf\n",
    "from six.moves import xrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UI4ZC__4FQuL",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# libraries required for visualisation:\n",
    "from IPython.display import SVG, display\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# set numpy output to something sensible\n",
    "np.set_printoptions(precision=8, edgeitems=6, linewidth=200, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4xYY-TUd9aiD",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import svgwrite # conda install -c omnia svgwrite=1.1.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "NzPSD-XRFQuP",
    "outputId": "daa0dd33-6d59-4d15-f437-d8ec787c8884",
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'logging'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogging\u001b[49m\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTensorFlow Version: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, tf\u001b[38;5;241m.\u001b[39m__version__)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'logging'"
     ]
    }
   ],
   "source": [
    "tf.logging.info(\"TensorFlow Version: %s\", tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NkFS0E1zFQuU",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import our command line tools\n",
    "from sketch_rnn_train import *\n",
    "from model import *\n",
    "from utils import *\n",
    "from rnn import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GBde4xkEFQuX",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# little function that displays vector images and saves them to .svg\n",
    "def draw_strokes(data, factor=0.2, svg_filename = '/tmp/sketch_rnn/svg/sample.svg'):\n",
    "  tf.gfile.MakeDirs(os.path.dirname(svg_filename))\n",
    "  min_x, max_x, min_y, max_y = get_bounds(data, factor)\n",
    "  dims = (50 + max_x - min_x, 50 + max_y - min_y)\n",
    "  dwg = svgwrite.Drawing(svg_filename, size=dims)\n",
    "  dwg.add(dwg.rect(insert=(0, 0), size=dims,fill='white'))\n",
    "  lift_pen = 1\n",
    "  abs_x = 25 - min_x \n",
    "  abs_y = 25 - min_y\n",
    "  p = \"M%s,%s \" % (abs_x, abs_y)\n",
    "  command = \"m\"\n",
    "  for i in xrange(len(data)):\n",
    "    if (lift_pen == 1):\n",
    "      command = \"m\"\n",
    "    elif (command != \"l\"):\n",
    "      command = \"l\"\n",
    "    else:\n",
    "      command = \"\"\n",
    "    x = float(data[i,0])/factor\n",
    "    y = float(data[i,1])/factor\n",
    "    lift_pen = data[i, 2]\n",
    "    p += command+str(x)+\",\"+str(y)+\" \"\n",
    "  the_color = \"black\"\n",
    "  stroke_width = 1\n",
    "  dwg.add(dwg.path(p).stroke(the_color,stroke_width).fill(\"none\"))\n",
    "  dwg.save()\n",
    "  display(SVG(dwg.tostring()))\n",
    "\n",
    "# generate a 2D grid of many vector drawings\n",
    "def make_grid_svg(s_list, grid_space=10.0, grid_space_x=16.0):\n",
    "  def get_start_and_end(x):\n",
    "    x = np.array(x)\n",
    "    x = x[:, 0:2]\n",
    "    x_start = x[0]\n",
    "    x_end = x.sum(axis=0)\n",
    "    x = x.cumsum(axis=0)\n",
    "    x_max = x.max(axis=0)\n",
    "    x_min = x.min(axis=0)\n",
    "    center_loc = (x_max+x_min)*0.5\n",
    "    return x_start-center_loc, x_end\n",
    "  x_pos = 0.0\n",
    "  y_pos = 0.0\n",
    "  result = [[x_pos, y_pos, 1]]\n",
    "  for sample in s_list:\n",
    "    s = sample[0]\n",
    "    grid_loc = sample[1]\n",
    "    grid_y = grid_loc[0]*grid_space+grid_space*0.5\n",
    "    grid_x = grid_loc[1]*grid_space_x+grid_space_x*0.5\n",
    "    start_loc, delta_pos = get_start_and_end(s)\n",
    "\n",
    "    loc_x = start_loc[0]\n",
    "    loc_y = start_loc[1]\n",
    "    new_x_pos = grid_x+loc_x\n",
    "    new_y_pos = grid_y+loc_y\n",
    "    result.append([new_x_pos-x_pos, new_y_pos-y_pos, 0])\n",
    "\n",
    "    result += s.tolist()\n",
    "    result[-1][2] = 1\n",
    "    x_pos = new_x_pos+delta_pos[0]\n",
    "    y_pos = new_y_pos+delta_pos[1]\n",
    "  return np.array(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "if7-UyxzFQuY"
   },
   "source": [
    "define the path of the model you want to load, and also the path of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Dipv1EbsFQuZ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data_dir = 'http://github.com/hardmaru/sketch-rnn-datasets/raw/master/aaron_sheep/'\n",
    "model_dir = 'logs-lstm-hyper'\n",
    "# models_root_dir = '/tmp/sketch_rnn/models'\n",
    "# model_dir = '/tmp/sketch_rnn/models/aaron_sheep/layer_norm'\\\n",
    "data_dir = 'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "eaSqI0fIFQub",
    "outputId": "06df45a6-cc86-4f50-802e-25ae185037f7"
   },
   "outputs": [],
   "source": [
    "download_pretrained_models(models_root_dir=models_root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G4sRuxyn_1aO",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_env_compatible(data_dir, model_dir):\n",
    "  \"\"\"Loads environment for inference mode, used in jupyter notebook.\"\"\"\n",
    "  # modified https://github.com/tensorflow/magenta/blob/master/magenta/models/sketch_rnn/sketch_rnn_train.py\n",
    "  # to work with depreciated tf.HParams functionality\n",
    "  model_params = sketch_rnn_model.get_default_hparams()\n",
    "  with tf.gfile.Open(os.path.join(model_dir, 'model_config.json'), 'r') as f:\n",
    "    data = json.load(f)\n",
    "  fix_list = ['conditional', 'is_training', 'use_input_dropout', 'use_output_dropout', 'use_recurrent_dropout']\n",
    "  for fix in fix_list:\n",
    "    data[fix] = (data[fix] == 1)\n",
    "  model_params.parse_json(json.dumps(data))\n",
    "  return load_dataset(data_dir, model_params, inference_mode=True)\n",
    "\n",
    "def load_model_compatible(model_dir):\n",
    "  \"\"\"Loads model for inference mode, used in jupyter notebook.\"\"\"\n",
    "  # modified https://github.com/tensorflow/magenta/blob/master/magenta/models/sketch_rnn/sketch_rnn_train.py\n",
    "  # to work with depreciated tf.HParams functionality\n",
    "  model_params = sketch_rnn_model.get_default_hparams()\n",
    "  with tf.gfile.Open(os.path.join(model_dir, 'model_config.json'), 'r') as f:\n",
    "    data = json.load(f)\n",
    "  fix_list = ['conditional', 'is_training', 'use_input_dropout', 'use_output_dropout', 'use_recurrent_dropout']\n",
    "  for fix in fix_list:\n",
    "    data[fix] = (data[fix] == 1)\n",
    "  model_params.parse_json(json.dumps(data))\n",
    "\n",
    "  model_params.batch_size = 1  # only sample one at a time\n",
    "  eval_model_params = sketch_rnn_model.copy_hparams(model_params)\n",
    "  eval_model_params.use_input_dropout = 0\n",
    "  eval_model_params.use_recurrent_dropout = 0\n",
    "  eval_model_params.use_output_dropout = 0\n",
    "  eval_model_params.is_training = 0\n",
    "  sample_model_params = sketch_rnn_model.copy_hparams(eval_model_params)\n",
    "  sample_model_params.max_seq_len = 1  # sample one point at a time\n",
    "  return [model_params, eval_model_params, sample_model_params]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "9m-jSAb3FQuf",
    "outputId": "debc045d-d15a-4b30-f747-fa4bcbd069fd",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total images <= max_seq_len is 12500\n",
      "total images <= max_seq_len is 12500\n",
      "INFO:tensorflow:normalizing_scale_factor 43.2371.\n"
     ]
    }
   ],
   "source": [
    "[train_set, valid_set, test_set, hps_model, eval_hps_model, sample_hps_model] = load_env_compatible(data_dir, model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 479
    },
    "colab_type": "code",
    "id": "1pHS8TSgFQui",
    "outputId": "50b0e14d-ff0f-43bf-d996-90e9e6a1491e",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Model using gpu.\n",
      "INFO:tensorflow:Input dropout mode = False.\n",
      "INFO:tensorflow:Output dropout mode = False.\n",
      "INFO:tensorflow:Recurrent dropout mode = True.\n",
      "WARNING:tensorflow:From /inspire/hdd/project/wuliqifa/yanjunchi-24040/hang/recon/sketch_rnn/model.py:89: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /inspire/hdd/project/wuliqifa/public/miniconda3/envs/sketch/lib/python3.10/site-packages/tensorflow/python/ops/rnn.py:441: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /inspire/hdd/project/wuliqifa/public/miniconda3/envs/sketch/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1260: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-27 19:49:35.451690: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2348] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.\n",
      "2025-12-27 19:49:35.452840: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2348] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.\n",
      "2025-12-27 19:49:35.889634: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2348] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.\n",
      "2025-12-27 19:49:35.890785: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2348] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.\n",
      "2025-12-27 19:49:35.910418: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 982 MB memory:  -> device: 0, name: NVIDIA H100 80GB HBM3, pci bus id: 0000:2a:00.0, compute capability: 9.0\n",
      "2025-12-27 19:49:35.912071: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 66683 MB memory:  -> device: 1, name: NVIDIA H100 80GB HBM3, pci bus id: 0000:3b:00.0, compute capability: 9.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /inspire/hdd/project/wuliqifa/public/miniconda3/envs/sketch/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1260: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "WARNING:tensorflow:From /inspire/hdd/project/wuliqifa/public/miniconda3/envs/sketch/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1260: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /inspire/hdd/project/wuliqifa/public/miniconda3/envs/sketch/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1260: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "INFO:tensorflow:Model using gpu.\n",
      "INFO:tensorflow:Input dropout mode = 0.\n",
      "INFO:tensorflow:Output dropout mode = 0.\n",
      "INFO:tensorflow:Recurrent dropout mode = 0.\n",
      "INFO:tensorflow:Model using gpu.\n",
      "INFO:tensorflow:Input dropout mode = 0.\n",
      "INFO:tensorflow:Output dropout mode = 0.\n",
      "INFO:tensorflow:Recurrent dropout mode = 0.\n"
     ]
    }
   ],
   "source": [
    "# construct the sketch-rnn model here:\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "reset_graph()\n",
    "model = Model(hps_model)\n",
    "eval_model = Model(eval_hps_model, reuse=True)\n",
    "sample_model = Model(sample_hps_model, reuse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1gxYLPTQFQuk",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-27 19:49:41.115976: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2348] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.\n",
      "2025-12-27 19:49:41.117560: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2348] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.\n",
      "2025-12-27 19:49:41.126006: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 982 MB memory:  -> device: 0, name: NVIDIA H100 80GB HBM3, pci bus id: 0000:2a:00.0, compute capability: 9.0\n",
      "2025-12-27 19:49:41.133186: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 66683 MB memory:  -> device: 1, name: NVIDIA H100 80GB HBM3, pci bus id: 0000:3b:00.0, compute capability: 9.0\n",
      "2025-12-27 19:49:41.211789: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "bVlDyfN_FQum",
    "outputId": "fb41ce20-4c7f-4991-e9f6-559ea9b34a31",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loading model logs-lstm-hyper/vector-203500.\n",
      "INFO:tensorflow:Restoring parameters from logs-lstm-hyper/vector-203500\n"
     ]
    }
   ],
   "source": [
    "# loads the weights from checkpoint into our model\n",
    "load_checkpoint(sess, model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EOblwpFeFQuq"
   },
   "source": [
    "We define two convenience functions to encode a stroke into a latent vector, and decode from latent vector to stroke."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tMFlV487FQur",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def encode(input_strokes):\n",
    "  strokes = to_big_strokes(input_strokes, max_len=177).tolist()\n",
    "  strokes.insert(0, [0, 0, 1, 0, 0])\n",
    "  seq_len = [len(input_strokes)]\n",
    "  draw_strokes(to_normal_strokes(np.array(strokes)))\n",
    "  print(seq_len)\n",
    "  return sess.run(eval_model.batch_z, feed_dict= \\\n",
    "                  {eval_model.input_data: [strokes], \n",
    "                   eval_model.sequence_lengths: seq_len})[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1D5CV7ZlFQut",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def decode(z_input=None, draw_mode=True, temperature=0.1, factor=0.2):\n",
    "  z = None\n",
    "  if z_input is not None:\n",
    "    z = [z_input]\n",
    "  sample_strokes, m = sample(sess, sample_model, seq_len=eval_model.hps.max_seq_len, temperature=temperature, z=z)\n",
    "  strokes = to_normal_strokes(sample_strokes)\n",
    "  if draw_mode:\n",
    "    draw_strokes(strokes, factor)\n",
    "  return strokes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from Dataset import Quickdraw414k\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_data = Quickdraw414k(mode=\"Test\")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_data, batch_size=1, shuffle=False, num_workers=0)\n",
    "it = iter(test_loader)\n",
    "data = netx(it)\n",
    "print(next(it))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sketch_list = \"../QuickDraw414k/picture_files/tiny_test_set.txt\"\n",
    "path_root1 = '../QuickDraw414k/picture_files/test'\n",
    "path_root2 = '../QuickDraw414k/coordinate_files/test'\n",
    "\n",
    "with open(sketch_list) as sketch_url_file:\n",
    "    sketch_url_list = sketch_url_file.readlines()\n",
    "    # img_urls = [os.path.join(path_root1, sketch_url.strip().split(' ')[\n",
    "    #     0]) for sketch_url in sketch_url_list]\n",
    "    # labels = [int(sketch_url.strip().split(' ')[-1])\n",
    "    #                for sketch_url in sketch_url_list]\n",
    "    class_map = dict()\n",
    "    for sketch_url in sketch_url_list:\n",
    "        cls_str, cls_int = sketch_url.strip().split(' ')\n",
    "        cls_str = cls_str.split('/')[0]\n",
    "        if cls_str not in class_map:\n",
    "            class_map[cls_str] = int(cls_int)\n",
    "print(class_map)\n",
    "import json\n",
    "with open('cls_map.json', 'w') as f:\n",
    "    json.dump(class_map, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 123
    },
    "colab_type": "code",
    "id": "fUOAvRQtFQuw",
    "outputId": "c8e9a1c3-28db-4263-ac67-62ffece1e1e0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get a sample drawing from the test set, and render it to .svg\n",
    "stroke = test_set.random_sample()\n",
    "draw_strokes(stroke)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j114Re2JFQuz"
   },
   "source": [
    "Let's try to encode the sample stroke into latent vector $z$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 123
    },
    "colab_type": "code",
    "id": "DBRjPBo-FQu0",
    "outputId": "e089dc78-88e3-44c6-ed7e-f1844471f47f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(len(stroke))\n",
    "z = encode(stroke)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "id": "-37v6eZLFQu5",
    "outputId": "5ddac2f2-5b3b-4cd7-b81f-7a8fa374aa6b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "_ = decode(z, temperature=0.7) # convert z back to drawing at temperature of 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M5ft6IEBFQu9"
   },
   "source": [
    "Create generated grid at various temperatures from 0.1 to 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 130
    },
    "colab_type": "code",
    "id": "BuhaZI0aFQu9",
    "outputId": "d87d4b00-30c2-4302-bec8-46566ef26922",
    "tags": []
   },
   "outputs": [],
   "source": [
    "stroke_list = []\n",
    "for i in range(10):\n",
    "  stroke_list.append([decode(z, draw_mode=False, temperature=0.1*i+0.1), [0, i]])\n",
    "stroke_grid = make_grid_svg(stroke_list)\n",
    "draw_strokes(stroke_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4xiwp3_DFQvB"
   },
   "source": [
    "Latent Space Interpolation Example between $z_0$ and $z_1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 123
    },
    "colab_type": "code",
    "id": "WSX0uvZTFQvD",
    "outputId": "cd67af4e-5ae6-4327-876e-e1385dadbafc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get a sample drawing from the test set, and render it to .svg\n",
    "z0 = z\n",
    "_ = decode(z0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 194
    },
    "colab_type": "code",
    "id": "jQf99TxOFQvH",
    "outputId": "4265bd5f-8c66-494e-b26e-d3ac874d69bb",
    "tags": []
   },
   "outputs": [],
   "source": [
    "stroke = test_set.random_sample()\n",
    "z1 = encode(stroke)\n",
    "_ = decode(z1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tDqJR8_eFQvK"
   },
   "source": [
    "Now we interpolate between sheep $z_0$ and sheep $z_1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_YkPNL5SFQvL",
    "tags": []
   },
   "outputs": [],
   "source": [
    "z_list = [] # interpolate spherically between z0 and z1\n",
    "N = 10\n",
    "for t in np.linspace(0, 1, N):\n",
    "  z_list.append(slerp(z0, z1, t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UoM-W1tQFQvM",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for every latent vector in z_list, sample a vector image\n",
    "reconstructions = []\n",
    "for i in range(N):\n",
    "  reconstructions.append([decode(z_list[i], draw_mode=False), [0, i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "mTqmlL6GFQvQ",
    "outputId": "062e015f-29c6-4e77-c6db-e403d5cabd59",
    "tags": []
   },
   "outputs": [],
   "source": [
    "stroke_grid = make_grid_svg(reconstructions)\n",
    "draw_strokes(stroke_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vFwPna6uFQvS"
   },
   "source": [
    "Let's load the Flamingo Model, and try Unconditional (Decoder-Only) Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HH-YclgNFQvT"
   },
   "outputs": [],
   "source": [
    "model_dir = '/tmp/sketch_rnn/models/flamingo/lstm_uncond'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-Znvy3KxFQvU"
   },
   "outputs": [],
   "source": [
    "[hps_model, eval_hps_model, sample_hps_model] = load_model_compatible(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "cqDNK1cYFQvZ",
    "outputId": "d346d57c-f51a-4286-ba55-705bc27d4d0d"
   },
   "outputs": [],
   "source": [
    "# construct the sketch-rnn model here:\n",
    "reset_graph()\n",
    "model = Model(hps_model)\n",
    "eval_model = Model(eval_hps_model, reuse=True)\n",
    "sample_model = Model(sample_hps_model, reuse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7wzerSI6FQvd"
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "6mzk8KjOFQvf",
    "outputId": "c450a6c6-22ee-4a58-8451-443462b42d58"
   },
   "outputs": [],
   "source": [
    "# loads the weights from checkpoint into our model\n",
    "load_checkpoint(sess, model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X88CgcyuFQvh",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# randomly unconditionally generate 10 examples\n",
    "N = 10\n",
    "reconstructions = []\n",
    "for i in range(N):\n",
    "  reconstructions.append([decode(temperature=0.5, draw_mode=False), [0, i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 149
    },
    "colab_type": "code",
    "id": "k57REtd_FQvj",
    "outputId": "8bd69652-9d1d-475e-fc64-f205cf6b9ed1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "stroke_grid = make_grid_svg(reconstructions)\n",
    "draw_strokes(stroke_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L-rJ0iUQFQvl"
   },
   "source": [
    "Let's load the owl model, and generate two sketches using two random IID gaussian latent vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "of4SWwGdFQvm"
   },
   "outputs": [],
   "source": [
    "model_dir = '/tmp/sketch_rnn/models/owl/lstm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "jJiSZFQeFQvp",
    "outputId": "f84360ca-c2be-482f-db57-41b5ecc05768"
   },
   "outputs": [],
   "source": [
    "[hps_model, eval_hps_model, sample_hps_model] = load_model_compatible(model_dir)\n",
    "# construct the sketch-rnn model here:\n",
    "reset_graph()\n",
    "model = Model(hps_model)\n",
    "eval_model = Model(eval_hps_model, reuse=True)\n",
    "sample_model = Model(sample_hps_model, reuse=True)\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "# loads the weights from checkpoint into our model\n",
    "load_checkpoint(sess, model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "colab_type": "code",
    "id": "vR4TDoi5FQvr",
    "outputId": "db08cb2c-952c-4949-d2b0-94c11351264b"
   },
   "outputs": [],
   "source": [
    "z_0 = np.random.randn(eval_model.hps.z_size)\n",
    "_ = decode(z_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "id": "ZX23lTnpFQvt",
    "outputId": "247052f2-a0f3-4046-83d6-d08e0429fafb"
   },
   "outputs": [],
   "source": [
    "z_1 = np.random.randn(eval_model.hps.z_size)\n",
    "_ = decode(z_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7FjQsF_2FQvv"
   },
   "source": [
    "Let's interpolate between the two owls $z_0$ and $z_1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u6G37E8_FQvw"
   },
   "outputs": [],
   "source": [
    "z_list = [] # interpolate spherically between z_0 and z_1\n",
    "N = 10\n",
    "for t in np.linspace(0, 1, N):\n",
    "  z_list.append(slerp(z_0, z_1, t))\n",
    "# for every latent vector in z_list, sample a vector image\n",
    "reconstructions = []\n",
    "for i in range(N):\n",
    "  reconstructions.append([decode(z_list[i], draw_mode=False, temperature=0.1), [0, i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 149
    },
    "colab_type": "code",
    "id": "OULjMktmFQvx",
    "outputId": "94b7b68e-9c57-4a1b-b216-83770fa4be81"
   },
   "outputs": [],
   "source": [
    "stroke_grid = make_grid_svg(reconstructions)\n",
    "draw_strokes(stroke_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OiXNC-YsFQv0"
   },
   "source": [
    "Let's load the model trained on both cats and buses!  catbus!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SL7WpDDQFQv0"
   },
   "outputs": [],
   "source": [
    "model_dir = '/tmp/sketch_rnn/models/catbus/lstm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "Cvk5WOqHFQv2",
    "outputId": "8081d53d-52d6-4d18-f973-a9dd44c897f2"
   },
   "outputs": [],
   "source": [
    "[hps_model, eval_hps_model, sample_hps_model] = load_model_compatible(model_dir)\n",
    "# construct the sketch-rnn model here:\n",
    "reset_graph()\n",
    "model = Model(hps_model)\n",
    "eval_model = Model(eval_hps_model, reuse=True)\n",
    "sample_model = Model(sample_hps_model, reuse=True)\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "# loads the weights from checkpoint into our model\n",
    "load_checkpoint(sess, model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "colab_type": "code",
    "id": "icvlBPVkFQv5",
    "outputId": "f7b415fe-4d65-4b00-c0eb-fb592597dba2"
   },
   "outputs": [],
   "source": [
    "z_1 = np.random.randn(eval_model.hps.z_size)\n",
    "_ = decode(z_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "uaNxd0LuFQv-",
    "outputId": "4de5ee9a-cf14-49f4-e5f5-399a0d0b8215"
   },
   "outputs": [],
   "source": [
    "z_0 = np.random.randn(eval_model.hps.z_size)\n",
    "_ = decode(z_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VtSYkS6mFQwC"
   },
   "source": [
    "Let's interpolate between a cat and a bus!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qIDYUxBEFQwD"
   },
   "outputs": [],
   "source": [
    "z_list = [] # interpolate spherically between z_1 and z_0\n",
    "N = 10\n",
    "for t in np.linspace(0, 1, N):\n",
    "  z_list.append(slerp(z_1, z_0, t))\n",
    "# for every latent vector in z_list, sample a vector image\n",
    "reconstructions = []\n",
    "for i in range(N):\n",
    "  reconstructions.append([decode(z_list[i], draw_mode=False, temperature=0.15), [0, i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "colab_type": "code",
    "id": "ZHmnSjSaFQwH",
    "outputId": "38fe3c7e-698b-4b19-8851-e7f3ff037744"
   },
   "outputs": [],
   "source": [
    "stroke_grid = make_grid_svg(reconstructions)\n",
    "draw_strokes(stroke_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "flZ_OgzCFQwJ"
   },
   "source": [
    "Why stop here? Let's load the model trained on both elephants and pigs!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S8WwK8FPFQwK"
   },
   "outputs": [],
   "source": [
    "model_dir = '/tmp/sketch_rnn/models/elephantpig/lstm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "meOH4AFXFQwM",
    "outputId": "764938a7-bbdc-4732-e688-a8a278ab3089"
   },
   "outputs": [],
   "source": [
    "[hps_model, eval_hps_model, sample_hps_model] = load_model_compatible(model_dir)\n",
    "# construct the sketch-rnn model here:\n",
    "reset_graph()\n",
    "model = Model(hps_model)\n",
    "eval_model = Model(eval_hps_model, reuse=True)\n",
    "sample_model = Model(sample_hps_model, reuse=True)\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "# loads the weights from checkpoint into our model\n",
    "load_checkpoint(sess, model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "foZiiYPdFQwO",
    "outputId": "a09fc4fb-110f-4280-8515-c9b673cb6b90"
   },
   "outputs": [],
   "source": [
    "z_0 = np.random.randn(eval_model.hps.z_size)\n",
    "_ = decode(z_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 163
    },
    "colab_type": "code",
    "id": "6Gaz3QG1FQwS",
    "outputId": "0cfc279c-1c59-419f-86d4-ed74d5e38a26"
   },
   "outputs": [],
   "source": [
    "z_1 = np.random.randn(eval_model.hps.z_size)\n",
    "_ = decode(z_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oVtr7NnGFQwU"
   },
   "source": [
    "Tribute to an episode of [South Park](https://en.wikipedia.org/wiki/An_Elephant_Makes_Love_to_a_Pig): The interpolation between an Elephant and a Pig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lJs9JbROFQwU"
   },
   "outputs": [],
   "source": [
    "z_list = [] # interpolate spherically between z_1 and z_0\n",
    "N = 10\n",
    "for t in np.linspace(0, 1, N):\n",
    "  z_list.append(slerp(z_0, z_1, t))\n",
    "# for every latent vector in z_list, sample a vector image\n",
    "reconstructions = []\n",
    "for i in range(N):\n",
    "  reconstructions.append([decode(z_list[i], draw_mode=False, temperature=0.15), [0, i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0FOuNfJMFQwW"
   },
   "outputs": [],
   "source": [
    "stroke_grid = make_grid_svg(reconstructions, grid_space_x=25.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 130
    },
    "colab_type": "code",
    "id": "bZ6zpdiMFQwX",
    "outputId": "70679bd1-4dba-4c08-b39f-bbde81d22019"
   },
   "outputs": [],
   "source": [
    "draw_strokes(stroke_grid, factor=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KUgVRGnSFQwa"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Sketch_RNN.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "sketch",
   "language": "python",
   "name": "sketch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
