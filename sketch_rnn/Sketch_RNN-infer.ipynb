{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tDybPQiEFQuJ"
   },
   "source": [
    "In this notebook, we will show how to load pre-trained models and draw things with sketch-rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NkFS0E1zFQuU",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import the required libraries\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "# import cPickle\n",
    "import codecs\n",
    "import collections\n",
    "import os\n",
    "import math\n",
    "import json\n",
    "import tensorflow as tf\n",
    "from six.moves import xrange\n",
    "\n",
    "# libraries required for visualisation:\n",
    "from IPython.display import SVG, display\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# set numpy output to something sensible\n",
    "np.set_printoptions(precision=8, edgeitems=6, linewidth=200, suppress=True)\n",
    "\n",
    "import svgwrite # conda install -c omnia svgwrite=1.1.6\n",
    "\n",
    "# import our command line tools\n",
    "from sketch_rnn_train import *\n",
    "from model import *\n",
    "from utils import *\n",
    "from rnn import *\n",
    "from Utils import draw_three"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GBde4xkEFQuX",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# little function that displays vector images and saves them to .svg\n",
    "def draw_strokes(data, factor=0.2, svg_filename = '/tmp/sketch_rnn/svg/sample.svg'):\n",
    "  tf.gfile.MakeDirs(os.path.dirname(svg_filename))\n",
    "  min_x, max_x, min_y, max_y = get_bounds(data, factor)\n",
    "  dims = (50 + max_x - min_x, 50 + max_y - min_y)\n",
    "  dwg = svgwrite.Drawing(svg_filename, size=dims)\n",
    "  dwg.add(dwg.rect(insert=(0, 0), size=dims,fill='white'))\n",
    "  lift_pen = 1\n",
    "  abs_x = 25 - min_x \n",
    "  abs_y = 25 - min_y\n",
    "  p = \"M%s,%s \" % (abs_x, abs_y)\n",
    "  command = \"m\"\n",
    "  for i in xrange(len(data)):\n",
    "    if (lift_pen == 1):\n",
    "      command = \"m\"\n",
    "    elif (command != \"l\"):\n",
    "      command = \"l\"\n",
    "    else:\n",
    "      command = \"\"\n",
    "    x = float(data[i,0])/factor\n",
    "    y = float(data[i,1])/factor\n",
    "    lift_pen = data[i, 2]\n",
    "    p += command+str(x)+\",\"+str(y)+\" \"\n",
    "  the_color = \"black\"\n",
    "  stroke_width = 1\n",
    "  dwg.add(dwg.path(p).stroke(the_color,stroke_width).fill(\"none\"))\n",
    "  dwg.save()\n",
    "  display(SVG(dwg.tostring()))\n",
    "\n",
    "# generate a 2D grid of many vector drawings\n",
    "def make_grid_svg(s_list, grid_space=10.0, grid_space_x=16.0):\n",
    "  def get_start_and_end(x):\n",
    "    x = np.array(x)\n",
    "    x = x[:, 0:2]\n",
    "    x_start = x[0]\n",
    "    x_end = x.sum(axis=0)\n",
    "    x = x.cumsum(axis=0)\n",
    "    x_max = x.max(axis=0)\n",
    "    x_min = x.min(axis=0)\n",
    "    center_loc = (x_max+x_min)*0.5\n",
    "    return x_start-center_loc, x_end\n",
    "  x_pos = 0.0\n",
    "  y_pos = 0.0\n",
    "  result = [[x_pos, y_pos, 1]]\n",
    "  for sample in s_list:\n",
    "    s = sample[0]\n",
    "    grid_loc = sample[1]\n",
    "    grid_y = grid_loc[0]*grid_space+grid_space*0.5\n",
    "    grid_x = grid_loc[1]*grid_space_x+grid_space_x*0.5\n",
    "    start_loc, delta_pos = get_start_and_end(s)\n",
    "\n",
    "    loc_x = start_loc[0]\n",
    "    loc_y = start_loc[1]\n",
    "    new_x_pos = grid_x+loc_x\n",
    "    new_y_pos = grid_y+loc_y\n",
    "    result.append([new_x_pos-x_pos, new_y_pos-y_pos, 0])\n",
    "\n",
    "    result += s.tolist()\n",
    "    result[-1][2] = 1\n",
    "    x_pos = new_x_pos+delta_pos[0]\n",
    "    y_pos = new_y_pos+delta_pos[1]\n",
    "  return np.array(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "if7-UyxzFQuY"
   },
   "source": [
    "define the path of the model you want to load, and also the path of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G4sRuxyn_1aO",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data_dir = 'http://github.com/hardmaru/sketch-rnn-datasets/raw/master/aaron_sheep/'\n",
    "model_dir = 'logs-lstm-hyper-cls'\n",
    "# models_root_dir = '/tmp/sketch_rnn/models'\n",
    "# model_dir = '/tmp/sketch_rnn/models/aaron_sheep/layer_norm'\\\n",
    "data_dir = 'data'\n",
    "\n",
    "def load_env_compatible(data_dir, model_dir):\n",
    "  \"\"\"Loads environment for inference mode, used in jupyter notebook.\"\"\"\n",
    "  # modified https://github.com/tensorflow/magenta/blob/master/magenta/models/sketch_rnn/sketch_rnn_train.py\n",
    "  # to work with depreciated tf.HParams functionality\n",
    "  model_params = sketch_rnn_model.get_default_hparams()\n",
    "  with tf.gfile.Open(os.path.join(model_dir, 'model_config.json'), 'r') as f:\n",
    "    data = json.load(f)\n",
    "  fix_list = ['conditional', 'is_training', 'use_input_dropout', 'use_output_dropout', 'use_recurrent_dropout']\n",
    "  for fix in fix_list:\n",
    "    data[fix] = (data[fix] == 1)\n",
    "  model_params.parse_json(json.dumps(data))\n",
    "  print(model_params)\n",
    "  model_params.data_set=['cat.npz']\n",
    "  return load_dataset(data_dir, model_params, inference_mode=True)\n",
    "\n",
    "def load_model_compatible(model_dir):\n",
    "  \"\"\"Loads model for inference mode, used in jupyter notebook.\"\"\"\n",
    "  # modified https://github.com/tensorflow/magenta/blob/master/magenta/models/sketch_rnn/sketch_rnn_train.py\n",
    "  # to work with depreciated tf.HParams functionality\n",
    "  model_params = sketch_rnn_model.get_default_hparams()\n",
    "  with tf.gfile.Open(os.path.join(model_dir, 'model_config.json'), 'r') as f:\n",
    "    data = json.load(f)\n",
    "  fix_list = ['conditional', 'is_training', 'use_input_dropout', 'use_output_dropout', 'use_recurrent_dropout']\n",
    "  for fix in fix_list:\n",
    "    data[fix] = (data[fix] == 1)\n",
    "  model_params.parse_json(json.dumps(data))\n",
    "  print(model_params)\n",
    "\n",
    "  model_params.batch_size = 1  # only sample one at a time\n",
    "  eval_model_params = sketch_rnn_model.copy_hparams(model_params)\n",
    "  eval_model_params.use_input_dropout = 0\n",
    "  eval_model_params.use_recurrent_dropout = 0\n",
    "  eval_model_params.use_output_dropout = 0\n",
    "  eval_model_params.is_training = 0\n",
    "  sample_model_params = sketch_rnn_model.copy_hparams(eval_model_params)\n",
    "  sample_model_params.max_seq_len = 1  # sample one point at a time\n",
    "  return [model_params, eval_model_params, sample_model_params]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 479
    },
    "colab_type": "code",
    "id": "1pHS8TSgFQui",
    "outputId": "50b0e14d-ff0f-43bf-d996-90e9e6a1491e",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('augment_stroke_prob', 0.1), ('batch_size', 100), ('class_embed_dim', 32), ('cond_on_class', True), ('conditional', True), ('data_set', ['butterfly.npz', 'cake.npz', 'cat.npz', 'sheep.npz', 'fish.npz']), ('dec_model', 'hyper'), ('dec_rnn_size', 512), ('decay_rate', 0.9999), ('enc_model', 'lstm'), ('enc_rnn_size', 256), ('grad_clip', 1.0), ('input_dropout_prob', 0.9), ('is_training', True), ('kl_decay_rate', 0.99995), ('kl_tolerance', 0.2), ('kl_weight', 0.5), ('kl_weight_start', 0.01), ('learning_rate', 0.001), ('max_seq_len', 177), ('min_learning_rate', 1e-05), ('num_classes', 5), ('num_mixture', 20), ('num_steps', 10000000), ('output_dropout_prob', 0.9), ('random_scale_factor', 0.15), ('recurrent_dropout_prob', 0.9), ('save_every', 500), ('use_input_dropout', False), ('use_output_dropout', False), ('use_recurrent_dropout', True), ('z_size', 128)]\n",
      "(70000,)\n",
      "INFO:tensorflow:Dataset combined: 75000 (70000/2500/2500), avg len 69\n",
      "INFO:tensorflow:model_params.max_seq_len 177.\n",
      "total images <= max_seq_len is 70000\n",
      "total images <= max_seq_len is 2500\n",
      "total images <= max_seq_len is 2500\n",
      "INFO:tensorflow:normalizing_scale_factor 43.1702.\n",
      "[('augment_stroke_prob', 0.1), ('batch_size', 100), ('class_embed_dim', 32), ('cond_on_class', True), ('conditional', True), ('data_set', ['cat.npz']), ('dec_model', 'hyper'), ('dec_rnn_size', 512), ('decay_rate', 0.9999), ('enc_model', 'lstm'), ('enc_rnn_size', 256), ('grad_clip', 1.0), ('input_dropout_prob', 0.9), ('is_training', True), ('kl_decay_rate', 0.99995), ('kl_tolerance', 0.2), ('kl_weight', 0.5), ('kl_weight_start', 0.01), ('learning_rate', 0.001), ('max_seq_len', 177), ('min_learning_rate', 1e-05), ('num_classes', 5), ('num_mixture', 20), ('num_steps', 10000000), ('output_dropout_prob', 0.9), ('random_scale_factor', 0.15), ('recurrent_dropout_prob', 0.9), ('save_every', 500), ('use_input_dropout', False), ('use_output_dropout', False), ('use_recurrent_dropout', True), ('z_size', 128)]\n",
      "INFO:tensorflow:Model using gpu.\n",
      "INFO:tensorflow:Input dropout mode = False.\n",
      "INFO:tensorflow:Output dropout mode = False.\n",
      "INFO:tensorflow:Recurrent dropout mode = True.\n",
      "INFO:tensorflow:Model using gpu.\n",
      "INFO:tensorflow:Input dropout mode = 0.\n",
      "INFO:tensorflow:Output dropout mode = 0.\n",
      "INFO:tensorflow:Recurrent dropout mode = 0.\n",
      "INFO:tensorflow:Model using gpu.\n",
      "INFO:tensorflow:Input dropout mode = 0.\n",
      "INFO:tensorflow:Output dropout mode = 0.\n",
      "INFO:tensorflow:Recurrent dropout mode = 0.\n"
     ]
    }
   ],
   "source": [
    "[train_set, valid_set, test_set, hps_model, eval_hps_model, sample_hps_model] = load_env_compatible(data_dir, model_dir)\n",
    "\n",
    "# construct the sketch-rnn model here:\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "reset_graph()\n",
    "hps_model.max_seq_len = 177\n",
    "cond_on_class = True\n",
    "hps_model.cond_on_class = cond_on_class\n",
    "eval_hps_model.cond_on_class = cond_on_class\n",
    "sample_hps_model.cond_on_class = cond_on_class\n",
    "print(hps_model)\n",
    "model = Model(hps_model)\n",
    "eval_model = Model(eval_hps_model, reuse=True)\n",
    "sample_model = Model(sample_hps_model, reuse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52 67 261 54 119\n"
     ]
    }
   ],
   "source": [
    "cls_map = json.load(open('cls_map.json', 'r'))\n",
    "print(cls_map['butterfly'], cls_map['cat'],cls_map['sheep'],cls_map['cake'], cls_map['fish'])\n",
    "class_names = json.load(open('cls_map_i2s.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "bVlDyfN_FQum",
    "outputId": "fb41ce20-4c7f-4991-e9f6-559ea9b34a31",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-03 18:38:00.260440: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2348] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.\n",
      "2026-01-03 18:38:00.261599: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2348] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.\n",
      "2026-01-03 18:38:00.265706: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 78765 MB memory:  -> device: 0, name: NVIDIA H100 80GB HBM3, pci bus id: 0000:3b:00.0, compute capability: 9.0\n",
      "2026-01-03 18:38:00.266888: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 53809 MB memory:  -> device: 1, name: NVIDIA H100 80GB HBM3, pci bus id: 0000:4c:00.0, compute capability: 9.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loading model logs-lstm-hyper-cls/vector-86000.\n",
      "INFO:tensorflow:Restoring parameters from logs-lstm-hyper-cls/vector-86000\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# loads the weights from checkpoint into our model\n",
    "load_checkpoint(sess, model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EOblwpFeFQuq"
   },
   "source": [
    "We define two convenience functions to encode a stroke into a latent vector, and decode from latent vector to stroke."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def encode(input_strokes):\n",
    "  strokes = to_big_strokes(input_strokes, max_len=177).tolist()\n",
    "  strokes.insert(0, [0, 0, 1, 0, 0])\n",
    "  seq_len = [len(input_strokes)]\n",
    "  # draw_strokes(to_normal_strokes(np.array(strokes)))\n",
    "  return sess.run(eval_model.batch_z, feed_dict= \\\n",
    "                  {eval_model.input_data: [strokes], \n",
    "                   eval_model.sequence_lengths: seq_len})[0]\n",
    "\n",
    "def decode(z_input=None, draw_mode=True, temperature=0.1, factor=0.2,class_id=67):\n",
    "  z = None\n",
    "  if z_input is not None:\n",
    "    z = [z_input]\n",
    "  sample_strokes, m = sample(sess, sample_model, seq_len=eval_model.hps.max_seq_len, temperature=temperature, z=z, class_id=class_id)\n",
    "  strokes = to_normal_strokes(sample_strokes)\n",
    "  if draw_mode:\n",
    "    draw_strokes(strokes, factor)\n",
    "  return strokes\n",
    "\n",
    "from Dataset import Quickdraw414k\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_image(model, image_tensor, device='cuda', top_k=5):\n",
    "    \"\"\"\n",
    "    对图像进行预测\n",
    "    \"\"\"\n",
    "    # 将图像移动到设备\n",
    "    image_tensor = image_tensor.to(device)\n",
    "    \n",
    "    # 前向传播\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image_tensor)\n",
    "        # print(outputs)\n",
    "        probabilities = F.softmax(outputs, dim=1)\n",
    "    \n",
    "    # 获取top-k预测结果\n",
    "    top_probs, top_indices = torch.topk(probabilities, k=top_k)\n",
    "    \n",
    "    # 转换为Python标量\n",
    "    top_probs = top_probs.cpu().numpy()[0]\n",
    "    top_indices = top_indices.cpu().numpy()[0]\n",
    "    \n",
    "    return top_indices, top_probs\n",
    "\n",
    "def test(seq, model, verbose=False):\n",
    "    index_neg = np.where(seq == -1)[0]\n",
    "    if len(index_neg) == 0:\n",
    "        seq = off2abs(seq)\n",
    "    \n",
    "    # img = stp(seq)\n",
    "    img = draw_three(seq, stroke_flag=0)\n",
    "    ori = img\n",
    "    seq[:, 0:2] = seq[:, 0:2] / 256\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        # mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]\n",
    "        # transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "    ])\n",
    "    # 使用torchvision增强\n",
    "    img = transform(img)\n",
    "    img = torch.unsqueeze(img, dim=0)\n",
    "    # sketch_img_raw = transform(img_raw)\n",
    "    \n",
    "    # 处理坐标并生成图像\n",
    "    \n",
    "    # 进行预测\n",
    "    top_indices, top_probs = predict_image(\n",
    "        model=model,\n",
    "        image_tensor=img,\n",
    "        device='cpu',\n",
    "        top_k=5\n",
    "    )\n",
    "    \n",
    "    # 显示结果\n",
    "    if verbose:\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"预测结果:\")\n",
    "        print(\"-\"*50)\n",
    "\n",
    "        for i, (class_idx, prob) in enumerate(zip(top_indices, top_probs)):\n",
    "            class_name = class_names[str(class_idx)] if class_idx < len(class_names) else f\"Class_{class_idx}\"\n",
    "            print(f\"{i+1}. {class_name} (ID: {class_idx}): {prob*100:.2f}%\")\n",
    "\n",
    "        print(\"=\"*50)\n",
    "    return top_indices, top_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "def stp(\n",
    "    strokes,\n",
    "    out_size=224,\n",
    "    render_size=512,\n",
    "    padding=32,\n",
    "    line_width=6,\n",
    "    bg_color=(255, 255, 255),\n",
    "    fg_color=(0, 0, 0),\n",
    "):\n",
    "    \"\"\"\n",
    "    strokes: (T,3) numpy array, [dx, dy, pen_up]\n",
    "    return: PIL.Image RGB, size=(out_size, out_size)\n",
    "    \"\"\"\n",
    "\n",
    "    s = np.asarray(strokes, dtype=np.float32)\n",
    "    xy = np.cumsum(s[:, :2], axis=0)\n",
    "    pen_up = s[:, 2].astype(np.int32)\n",
    "\n",
    "    # bounding box\n",
    "    min_xy = xy.min(axis=0)\n",
    "    max_xy = xy.max(axis=0)\n",
    "    wh = np.maximum(max_xy - min_xy, 1e-6)\n",
    "\n",
    "    scale = (render_size - 2 * padding) / max(wh)\n",
    "    xy = (xy - min_xy) * scale\n",
    "\n",
    "    # center\n",
    "    wh2 = wh * scale\n",
    "    offset = np.array([\n",
    "        (render_size - wh2[0]) / 2,\n",
    "        (render_size - wh2[1]) / 2\n",
    "    ])\n",
    "    xy += offset\n",
    "\n",
    "    # draw at high resolution\n",
    "    img = Image.new(\"RGB\", (render_size, render_size), bg_color)\n",
    "    draw = ImageDraw.Draw(img)\n",
    "\n",
    "    prev = tuple(xy[0])\n",
    "    for i in range(1, len(xy)):\n",
    "        cur = tuple(xy[i])\n",
    "        if pen_up[i - 1] == 0:\n",
    "            draw.line([prev, cur], fill=fg_color, width=line_width)\n",
    "        prev = cur\n",
    "\n",
    "    # downsample to model input size\n",
    "    img = img.resize((out_size, out_size), Image.BILINEAR)\n",
    "    return img\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def convert_seq(strokes, out_range=256, margin=8, stroke_flag_for_break=0):\n",
    "    \"\"\"\n",
    "    strokes: (T,3) from sketch-rnn decode() AFTER to_normal_strokes:\n",
    "             [dx, dy, pen_up] where pen_up==1 means lift pen (break)\n",
    "    returns: (T,3) absolute coords in [0, out_range), and state compatible with draw_three(stroke_flag=0)\n",
    "             i.e. state==0 means break stroke, state==1 means continue\n",
    "    \"\"\"\n",
    "    s = np.asarray(strokes, dtype=np.float32)\n",
    "    dxdy = s[:, :2]\n",
    "    pen_up = s[:, 2].astype(np.float32)  # 1 means break in sketch-rnn\n",
    "\n",
    "    # 1) relative -> absolute\n",
    "    xy = np.cumsum(dxdy, axis=0)\n",
    "\n",
    "    # 2) normalize bbox -> [margin, out_range-margin]\n",
    "    min_xy = xy.min(axis=0)\n",
    "    max_xy = xy.max(axis=0)\n",
    "    wh = np.maximum(max_xy - min_xy, 1e-6)\n",
    "\n",
    "    scale = (out_range - 2 * margin) / max(wh[0], wh[1])\n",
    "    xy = (xy - min_xy) * scale + margin\n",
    "\n",
    "    # 3) pen semantics mapping:\n",
    "    # sketch-rnn pen_up==1 means break\n",
    "    # your draw_three with stroke_flag=0 expects state==0 means break\n",
    "    # => state = 1 - pen_up  (so break becomes 0, continue becomes 1)\n",
    "    state = 1.0 - pen_up\n",
    "\n",
    "    seq = np.concatenate([xy, state[:, None]], axis=1).astype(np.float32)\n",
    "    return seq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 123
    },
    "colab_type": "code",
    "id": "fUOAvRQtFQuw",
    "outputId": "c8e9a1c3-28db-4263-ac67-62ffece1e1e0",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" baseProfile=\"full\" height=\"88.10501554049551\" version=\"1.1\" width=\"103.27752828598022\"><defs/><rect fill=\"white\" height=\"88.10501554049551\" width=\"103.27752828598022\" x=\"0\" y=\"0\"/><path d=\"M53.72353780083358,33.57073247432709 m-4.169545769691467,-0.11582071892917156 l-3.242979943752289,0.5791035667061806 -3.242979943752289,1.9689521193504333 l-3.242979943752289,2.895517945289612 -3.358800709247589,6.254318952560425 l-0.8107449859380722,4.401187300682068 0.0,4.517008066177368 l0.6949242949485779,1.3898485898971558 2.0847728848457336,2.4322350323200226 l4.285366535186768,2.4322350323200226 6.370139122009277,1.7373107373714447 l1.9689521193504333,0.0 4.169545769691467,1.0423864424228668 l5.211932063102722,0.0 9.61311936378479,-4.517008066177368 l2.7796971797943115,-3.1271594762802124 0.5791035667061806,-1.9689521193504333 l-0.11582071892917156,-2.7796971797943115 -1.505669355392456,-2.895517945289612 l-5.791035890579224,-7.991629242897034 -1.7373107373714447,-3.1271594762802124 l-1.505669355392456,-1.7373107373714447 -1.505669355392456,-0.9265657514333725 l-6.8334221839904785,-2.6638764142990112 -4.632828533649445,0.0 l-1.1582071334123611,0.9265657514333725 -0.34746214747428894,0.8107449859380722 m-3.1271594762802124,1.505669355392456 l-0.5791035667061806,-0.23164143785834312 -0.9265657514333725,-2.6638764142990112 l-0.6949242949485779,-6.601780652999878 1.0423864424228668,-0.11582071892917156 l2.3164142668247223,1.505669355392456 2.548055648803711,2.6638764142990112 l3.1271594762802124,4.169545769691467 m10.192222595214844,-0.5791035667061806 l1.7373107373714447,-0.23164143785834312 1.9689521193504333,-0.8107449859380722 l2.548055648803711,-2.3164142668247223 3.9379042387008667,-2.7796971797943115 l0.0,0.9265657514333725 -2.0847728848457336,3.011338710784912 l-2.895517945289612,5.906856656074524 -0.34746214747428894,3.5904422402381897 m-3.1271594762802124,6.370139122009277 l8.918195366859436,-1.3898485898971558 m-11.813713312149048,6.717601418495178 l4.632828533649445,0.11582071892917156 8.686553835868835,-2.548055648803711 l3.9379042387008667,-1.7373107373714447 m-14.24594759941101,6.8334221839904785 l4.748649299144745,0.0 3.1271594762802124,-0.6949242949485779 m-26.52294397354126,-6.601780652999878 l-10.308043956756592,0.0 -6.601780652999878,-1.1582071334123611 m17.952210903167725,4.285366535186768 l-3.011338710784912,1.3898485898971558 -2.548055648803711,0.5791035667061806 l-12.971919775009155,0.0 m17.14146614074707,1.505669355392456 l-2.0847728848457336,1.3898485898971558 -4.517008066177368,1.853131502866745 l-6.485959887504578,1.6214899718761444 -6.949242949485779,0.8107449859380722 \" fill=\"none\" stroke=\"black\" stroke-width=\"1\"/></svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get a sample drawing from the test set, and render it to .svg\n",
    "stroke = test_set.random_sample()\n",
    "draw_strokes(stroke)\n",
    "# stroke[:,0:2] = stroke[:,0:2]\n",
    "# img = stp(stroke)\n",
    "# n_img = torch.unsqueeze(trans(img), dim=0)\n",
    "# res = net(n_img)\n",
    "# print(res)\n",
    "# pred = res.data.max(1)[1].item()\n",
    "# print(pred, res[0][pred])\n",
    "# img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j114Re2JFQuz"
   },
   "source": [
    "Let's try to encode the sample stroke into latent vector $z$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 123
    },
    "colab_type": "code",
    "id": "DBRjPBo-FQu0",
    "outputId": "e089dc78-88e3-44c6-ed7e-f1844471f47f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(len(stroke))\n",
    "z = encode(stroke)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "id": "-37v6eZLFQu5",
    "outputId": "5ddac2f2-5b3b-4cd7-b81f-7a8fa374aa6b",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" baseProfile=\"full\" height=\"89.10191055387259\" version=\"1.1\" width=\"91.51044572816318\"><defs/><rect fill=\"white\" height=\"89.10191055387259\" width=\"91.51044572816318\" x=\"0\" y=\"0\"/><path d=\"M48.5238838020814,32.93323257472366 m-4.043378233909607,-0.07361011113971472 l-3.452935814857483,0.48103470355272293 -2.484547197818756,1.0537266731262207 l-4.646482765674591,3.8691118359565735 -2.53224641084671,3.4659171104431152 l-1.6744977235794067,4.0466538071632385 -0.7810106128454208,4.380552172660828 l1.5360011160373688,6.010810732841492 0.9643795341253281,1.559518724679947 l2.290901690721512,2.3878712952136993 2.5799918174743652,1.797495037317276 l2.796981632709503,1.1907119303941727 3.320525884628296,0.9988840669393539 l13.094842433929443,-0.7733794301748276 3.8386884331703186,-1.8304897844791412 l3.005569577217102,-2.198752760887146 1.7049729824066162,-1.9889059662818909 l1.6495780646800995,-3.5339131951332092 0.473409928381443,-2.934119701385498 l0.10485106147825718,-3.5589680075645447 -1.7081722617149353,-4.465229511260986 l-2.8970104455947876,-3.5076692700386047 -4.331529140472412,-3.1728896498680115 l-2.0946867763996124,-1.0698693990707397 -3.2536780834198,-1.0837031155824661 l-3.7283721566200256,-0.6075267866253853 m7.899349331855774,0.28513839468359947 l-0.41782986372709274,-0.19794819876551628 1.7579931020736694,-2.5627756118774414 l4.269501864910126,-3.9227697253227234 3.2602015137672424,-1.9781388342380524 l0.8994708210229874,0.9963999688625336 0.5857286229729652,2.686397135257721 l-7.762919267406687e-05,5.410736799240112 -0.021813621278852224,4.0130287408828735 m-28.67030143737793,-4.004186689853668 l-2.0172765851020813,-0.11236188933253288 -2.8357115387916565,0.5086715519428253 l-4.56708163022995,1.4275574684143066 -2.981722056865692,1.81149423122406 l-0.4164612293243408,0.792175754904747 0.897330716252327,2.6790782809257507 l4.520786106586456,4.775187969207764 m20.681464672088623,2.2726400196552277 l4.905124604701996,-2.0361365377902985 6.593198180198669,-1.7026540637016296 m-10.742717981338501,6.4900141954422 l12.70323634147644,0.862719789147377 0.4756481945514679,0.06547463592141867 m-12.225457429885864,1.5547876060009003 l5.202428102493286,1.8973462283611298 3.0473825335502625,1.1432400345802307 m-20.7332444190979,-6.836469769477844 l-6.143764853477478,-2.5260761380195618 -6.172354817390442,-1.076270416378975 l-0.8621364831924438,-0.20148901268839836 -0.48070482909679413,-0.1880834437906742 m11.63140058517456,5.4384249448776245 l-7.890161871910095,1.8975460529327393 -3.8282668590545654,1.663060039281845 m14.56485629081726,-0.9913671761751175 l-9.763210415840149,5.627994537353516 -1.468854546546936,1.158686950802803 l0.8131923526525497,-0.13495143502950668 \" fill=\"none\" stroke=\"black\" stroke-width=\"1\"/></svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "strokes = decode(z, temperature=0.7, class_id=54) # convert z back to drawing at temperature of 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M5ft6IEBFQu9"
   },
   "source": [
    "Create generated grid at various temperatures from 0.1 to 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 130
    },
    "colab_type": "code",
    "id": "BuhaZI0aFQu9",
    "outputId": "d87d4b00-30c2-4302-bec8-46566ef26922",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" baseProfile=\"full\" height=\"94.34421248097351\" version=\"1.1\" width=\"829.1254888635558\"><defs/><rect fill=\"white\" height=\"94.34421248097351\" width=\"829.1254888635558\" x=\"0\" y=\"0\"/><path d=\"M25,25 m0.0,0.0 m36.86345418449491,13.87514277274704 l-4.157481491565704,-0.042438446544110775 -3.627789616584778,0.8089579641819 l-3.028665781021118,1.5269798040390015 -3.181180953979492,2.6620259881019592 l-3.6645960807800293,5.141665935516357 -1.964380294084549,5.360885858535767 l-0.32231442630290985,5.121601819992065 0.8681260794401169,2.732630968093872 l1.8521066009998322,2.5906580686569214 2.7314558625221252,2.0920437574386597 l3.692699372768402,1.5173423290252686 6.355288028717041,0.8910230547189713 l6.178264617919922,-5.0579506023495924e-05 4.350947141647339,-0.8897217363119125 l4.106287956237793,-1.7247399687767029 3.2840651273727417,-2.3372867703437805 l2.2947508096694946,-2.7087998390197754 1.3943985104560852,-3.1424227356910706 l0.5545811727643013,-3.755832314491272 -0.8286619186401367,-4.9811238050460815 l-1.740349680185318,-3.35650235414505 -3.8178297877311707,-4.074594974517822 l-3.2360559701919556,-2.095116078853607 -3.382810056209564,-1.2581239640712738 l-5.1515138149261475,-0.6489671766757965 -2.4559152126312256,0.00024066417608992197 m10.543845891952515,1.2695194780826569 l-0.012024356983602047,-1.1199819296598434 1.3222706317901611,-2.1543218195438385 l2.305886596441269,-2.4897751212120056 3.4657418727874756,-2.3514215648174286 l2.3758402466773987,-0.8228940516710281 1.364922970533371,0.00011699969036271796 l0.6560462713241577,0.8232276886701584 0.20845972001552582,1.7834451794624329 l-0.5497745051980019,3.1385892629623413 -3.4385475516319275,8.123292326927185 l-0.6063660606741905,2.5779354572296143 m-26.436030864715576,-6.48946225643158 l-4.585062265396118,-4.795813858509064 -5.094922184944153,-3.7807732820510864 l0.2667110599577427,6.933619379997253 1.4018714427947998,4.425306618213654 m13.517922163009644,6.664108037948608 l-1.3737528026103973,-0.2561480924487114 -0.06705957930535078,0.5754590779542923 l0.560697428882122,-0.3700130432844162 m9.751363396644592,0.007046376704238355 l-0.2937733009457588,0.05804996006190777 0.09647808037698269,-0.12191264890134335 m-6.233541965484619,7.201535701751709 l-0.30325520783662796,-0.6874857097864151 4.164232909679413,-2.2336038947105408 l8.133652210235596,-1.6867409646511078 m-12.533944845199585,5.282339453697205 l11.732020378112793,-0.0963507778942585 5.9657222032547,0.9458798170089722 m-17.43555188179016,0.17903294414281845 l-0.5691473931074142,0.32556481659412384 -3.5144418478012085,4.361841678619385 l-2.7349385619163513,2.3009756207466125 m8.08167815208435,-7.821999192237854 l-3.1372901797294617,2.879144549369812 -6.271547079086304,6.382423639297485 m90.85465490352362,-28.46527774516062 l-4.194033741950989,-0.04739420022815466 -3.5473325848579407,0.7436889410018921 l-2.9787081480026245,1.4453060925006866 -3.3744394779205322,2.64171302318573 l-3.780820667743683,5.055407285690308 -1.9510003924369812,5.296092629432678 l-0.33017605543136597,3.7882253527641296 0.8323183655738831,3.366037607192993 l1.9102519750595093,2.744565010070801 2.5940218567848206,2.025134712457657 l3.8350969552993774,1.5748775005340576 4.64699000120163,0.7955140620470047 l7.432761788368225,-7.960284165164921e-05 5.98783016204834,-1.362663358449936 l3.647100329399109,-1.6410869359970093 3.0332064628601074,-2.2135376930236816 l2.2207124531269073,-2.7873387932777405 1.6124875843524933,-4.294256269931793 l0.004643881693482399,-4.9881622195243835 -1.7950616776943207,-4.492778778076172 l-2.2046267986297607,-2.886337637901306 -4.364742338657379,-3.353426456451416 l-3.317229151725769,-1.485445648431778 -3.3779820799827576,-0.7318512350320816 l-2.9802703857421875,0.0002711646993702743 -1.9684864580631256,0.5985178425908089 m10.404014587402344,1.476748138666153 l-0.19386855885386467,-0.8650239557027817 0.8394577354192734,-1.6661496460437775 l2.252100557088852,-2.4467240273952484 2.401723712682724,-1.838020384311676 l3.1095612049102783,-1.3028350472450256 3.0492570996284485,-0.27285659685730934 l1.6257525980472565,0.6834488362073898 0.7429832965135574,1.3329190015792847 l0.1164117269217968,1.845177412033081 -0.7983213663101196,3.055727779865265 l-2.7037963271141052,4.987497925758362 m-32.70091772079468,-2.0850716531276703 l-2.739689350128174,-5.294936895370483 -2.6927468180656433,-3.5474249720573425 l-1.2464434653520584,-0.8542667329311371 -0.47781702131032944,1.2542800605297089 l1.8508291244506836,9.000914096832275 0.9041298925876617,3.29689621925354 m12.445452213287354,8.143195509910583 l-1.747162640094757,-0.21578719839453697 m10.584701299667358,-0.16880745068192482 l-0.13847251422703266,-0.16457125544548035 m-7.235016822814941,5.233839750289917 l-1.549253910779953,-0.01711110584437847 -2.1443472802639008,-0.40196675807237625 l-3.850487470626831,-0.6109506264328957 -6.8430328369140625,-0.45195087790489197 m13.535453081130981,2.4496667087078094 l-9.015517234802246,1.8237119913101196 -5.908647775650024,2.315225452184677 m14.436802864074707,-2.5725695490837097 l-5.3554171323776245,2.5077325105667114 -4.613897502422333,3.392389714717865 m15.939264297485352,-8.408084511756897 l9.956867694854736,-1.6112954914569855 7.355209589004517,-0.4267698898911476 m-16.877880096435547,3.3804208040237427 l2.399723529815674,0.05158362444490194 5.10648250579834,1.003875881433487 m73.37005712091923,-21.9573777272808 l-4.157643914222717,-0.07297122851014137 -3.6626270413398743,0.7549180090427399 l-3.0918163061141968,1.6266554594039917 -3.768399655818939,3.6255058646202087 l-2.908167541027069,5.0272053480148315 -1.2236186116933823,3.6883825063705444 l-0.5571195110678673,5.228707194328308 0.6603460758924484,3.1920376420021057 l1.7768560349941254,2.912352979183197 2.4564822018146515,2.034274935722351 l3.8505271077156067,1.6190791130065918 5.971744060516357,0.8757517486810684 l7.04861044883728,-5.284620783641003e-05 6.075171232223511,-1.3160571455955505 l2.4812521040439606,-1.1318539828062057 4.178667366504669,-3.3045727014541626 l2.2397318482398987,-3.2358112931251526 0.9032148867845535,-3.1787535548210144 l-0.130772041156888,-5.023104548454285 -1.1036157608032227,-3.468964993953705 l-2.7410686016082764,-4.534918367862701 -3.9091619849205017,-3.4294897317886353 l-2.73063987493515,-1.4317621290683746 -5.132364630699158,-1.3105408847332 l-2.499515116214752,0.024961603339761496 -2.0488794147968292,0.7463693618774414 m9.959802627563477,0.9320580214262009 l0.10462194681167603,-1.5677864849567413 1.3199180364608765,-2.6783621311187744 l2.0979464054107666,-2.6916328072547913 1.4106594026088715,-1.1170248687267303 l1.9300797581672668,-0.7437377423048019 1.7055490612983704,5.285686711431481e-05 l0.9123031795024872,0.8469220250844955 1.0372769832611084,2.5958937406539917 l0.3972982242703438,3.8510748744010925 -0.42004797607660294,3.306386172771454 l-1.293283849954605,3.17446768283844 m-30.13939380645752,-2.3209381103515625 l-4.6403199434280396,-5.5117374658584595 -3.1846314668655396,-2.5980833172798157 l-0.5595831200480461,0.4856862500309944 -0.2063952572643757,1.7550662159919739 l0.7204780727624893,6.171098947525024 2.492305338382721,6.8866294622421265 m14.472122192382812,4.35896635055542 l1.2928447127342224,1.8414397537708282 m5.236709713935852,-2.0612308382987976 l0.30878838151693344,0.8507068455219269 m-6.3764578104019165,3.402509093284607 l-0.8063273876905441,-0.1706589013338089 -3.7653574347496033,0.358651764690876 l-7.467367649078369,1.9351673126220703 -5.33657431602478,2.02145054936409 m17.53526210784912,-3.441111445426941 l-8.05970311164856,1.9820070266723633 -6.137024760246277,2.8716877102851868 m14.054919481277466,-3.706023097038269 l-3.5901418328285217,0.0001374594558001263 -6.620841026306152,1.9616702198982239 l-3.6976099014282227,1.758834421634674 m19.14953112602234,-5.236276984214783 l10.79777717590332,-0.23673400282859802 7.199511528015137,0.917772576212883 m58.78222420138627,-19.514119939790362 l-4.220324754714966,-0.07906422950327396 -3.694886565208435,0.7352861016988754 l-2.7534013986587524,1.2570080161094666 -5.082581639289856,4.063895344734192 l-2.0119041204452515,3.0341437458992004 -2.0249468088150024,5.616441965103149 l-0.00012527936632977799,5.216457843780518 1.7705155909061432,3.751494884490967 l1.915043294429779,2.035737484693527 2.5194725394248962,1.6124904155731201 l3.9773431420326233,1.2838290631771088 4.175624847412109,0.6204414740204811 l7.603699564933777,-0.0002108148873958271 6.210143566131592,-1.445164829492569 l2.8749242424964905,-1.3591369986534119 2.7256402373313904,-2.1556276082992554 l1.3474157452583313,-1.7828036844730377 0.8983650058507919,-2.0184744894504547 l0.2695482224225998,-8.271105289459229 -1.2982562184333801,-3.3578652143478394 l-2.2486916184425354,-2.884298861026764 -2.118518650531769,-1.7417801916599274 l-4.944846928119659,-2.407205104827881 -5.279592275619507,-1.3633590936660767 l-1.9981279969215393,0.00023487558792112395 m11.281330585479736,1.401643455028534 l2.7909785509109497,-2.6204702258110046 3.0415406823158264,-1.9411475956439972 l3.3313578367233276,-0.9955935925245285 2.6056015491485596,0.005768711562268436 l0.7411268353462219,0.5222261697053909 0.5491241440176964,1.079246625304222 l-0.00018904931494034827,2.5833719968795776 -1.0772046446800232,2.7749821543693542 l-1.5887916088104248,2.109140455722809 -2.702696919441223,2.37091526389122 l-2.5379088521003723,1.4032919704914093 -1.9252607226371765,-8.149217137543019e-05 m-27.31563091278076,-5.415246486663818 l-3.920297622680664,-6.637926697731018 -3.9298582077026367,-4.775526821613312 l1.7383158206939697,8.102216124534607 1.7929378151893616,4.744711220264435 l1.6395682096481323,2.0836400985717773 m11.735947132110596,7.589468955993652 l-1.3925270736217499,-0.32551269978284836 -6.701735258102417,-0.8927000313997269 m9.22858715057373,2.210633307695389 l-7.437924146652222,1.2222716957330704 -3.396981954574585,1.247321292757988 m10.73448657989502,-0.5382993072271347 l-5.85543155670166,2.3222722113132477 -3.172883987426758,1.8337619304656982 m12.873739004135132,-6.691188216209412 l5.65341055393219,-0.8905878663063049 6.47806704044342,0.00010175373063248117 m-11.354204416275024,3.079456090927124 l7.4180275201797485,-0.22156460210680962 3.2662302255630493,0.000183543252205709 m-11.309925317764282,1.7750972509384155 l6.0632628202438354,0.5395493283867836 4.590606689453125,-0.227684173732996 m-17.172436714172363,-4.10756528377533 l0.4455792158842087,1.126798763871193 1.3094304502010345,-0.7474785298109055 l-0.44921278953552246,0.0042201479664072394 m87.68715478464401,-17.828512540859265 l-4.128155708312988,-0.10623263195157051 -3.568858802318573,0.7452476024627686 l-3.731479048728943,1.7086261510849 -2.2772598266601562,1.9273848831653595 l-3.777490556240082,5.2711039781570435 -2.963813543319702,9.052417278289795 l0.1680685207247734,3.5797131061553955 0.5710702762007713,1.7468968033790588 l1.975574940443039,2.94931560754776 3.3911457657814026,2.5784751772880554 l4.045595228672028,1.6445833444595337 4.210346341133118,0.7873943448066711 l7.214215993881226,0.3271491825580597 6.21537983417511,-1.194876804947853 l3.581560254096985,-1.5340006351470947 2.7433866262435913,-1.7445851862430573 l1.6904853284358978,-1.8328075110912323 1.2631215155124664,-2.117573171854019 l0.9550829231739044,-3.5270485281944275 0.06788437720388174,-3.774421811103821 l-1.5086904168128967,-6.129124760627747 -2.8643816709518433,-4.459564685821533 l-2.5880074501037598,-2.397390604019165 -3.0907103419303894,-1.97108656167984 l-3.213505744934082,-1.2359796464443207 -6.033012270927429,-1.1154759675264359 l-3.3572837710380554,0.40949277579784393 m-7.93654203414917,4.782021343708038 l0.17876794561743736,-3.002554476261139 1.734643280506134,-3.6580756306648254 l2.8652140498161316,-3.8744521141052246 0.7017570734024048,0.26717621833086014 l0.7613084465265274,1.490650624036789 2.4733324348926544,4.007008373737335 l1.539546251296997,1.1052390187978745 m11.171815395355225,1.4034540951251984 l4.560660719871521,-2.9948994517326355 5.394463539123535,-3.309575617313385 l0.4094855859875679,0.6735587865114212 -0.0002868503906938713,4.3674808740615845 l-0.9009712934494019,4.7002094984054565 m-21.14243507385254,7.535099983215332 l-0.8474669605493546,-0.1538078859448433 0.016094337916001678,1.230781376361847 l1.0674133151769638,0.4912975803017616 0.7419931143522263,-0.7476756721735001 m-4.028840661048889,1.1016000807285309 l-9.616106152534485,-1.021031066775322 -5.850210785865784,0.41725434362888336 m14.178246259689331,3.5533377528190613 l-9.774336218833923,0.8617513626813889 -5.174534916877747,1.7865876853466034 m13.51111888885498,-0.3923100605607033 l-5.216377377510071,2.059728056192398 -4.514124095439911,2.9304158687591553 m18.845547437667847,-8.914474248886108 l9.437454342842102,-1.5078961849212646 7.12497353553772,-0.08522330783307552 m-17.06058382987976,4.775595963001251 l9.627925157546997,0.08437414653599262 3.9272069931030273,0.726640596985817 l2.9638394713401794,1.3929763436317444 m-15.603412389755249,1.236540824174881 l2.949758470058441,-0.018227942055091262 7.55131721496582,1.6533732414245605 m63.80621830366181,-21.14261467297183 l-4.086974263191223,-0.1421978510916233 -3.470194637775421,0.7952451705932617 l-3.1310755014419556,1.5880119800567627 -3.6421188712120056,2.9010963439941406 l-3.1321898102760315,4.670179486274719 -1.7977793514728546,5.210815072059631 l-0.00023617796614416875,5.493093729019165 0.7196250557899475,1.6229248046875 l2.150728702545166,2.5367870926856995 2.9518046975135803,2.105983942747116 l4.913199841976166,1.657770723104477 4.742356240749359,0.6350900232791901 l6.948652863502502,-0.308868195861578 3.865330219268799,-0.6751798838376999 l3.604833483695984,-1.3654564321041107 3.4549951553344727,-2.3927900195121765 l2.4486352503299713,-2.922135293483734 2.739844024181366,-6.8310219049453735 l0.11336883530020714,-2.7138173580169678 -0.9199289977550507,-3.2216185331344604 l-1.0092145204544067,-1.6820640861988068 -2.87068247795105,-2.8477388620376587 l-8.579922318458557,-4.616199433803558 -3.520209491252899,-0.8388378471136093 l-1.7775684595108032,0.00024380038667004555 m-13.577070236206055,3.4684142470359802 l1.22605562210083,-1.3744044303894043 3.6641788482666016,-4.3908193707466125 l2.6120805740356445,-3.4438779950141907 2.7405917644500732,-2.5141876935958862 l5.392593145370483,0.07665071170777082 1.4608018100261688,0.6780910491943359 l1.5378916263580322,1.5267331898212433 2.4277667701244354,4.187578558921814 l2.0497970283031464,2.983543574810028 0.6148563697934151,-0.09626509621739388 l1.1494748294353485,-1.4149542152881622 3.602433204650879,-4.9811723828315735 l2.21051886677742,-2.033916413784027 2.482537180185318,-1.2287503480911255 l0.503755658864975,0.6114781647920609 0.44743891805410385,3.6400410532951355 m-28.005805015563965,11.777011156082153 l-5.902159214019775,0.12044615112245083 m13.580474853515625,0.47809869050979614 l-7.0661890506744385,1.9024351239204407 m10.279566049575806,0.7850401848554611 l-2.0356929302215576,1.693103313446045 -5.265641808509827,3.6315888166427612 l-1.2045910954475403,1.1806350946426392 -0.5053197592496872,0.9093004465103149 m13.341140747070312,-11.61705732345581 l7.4722737073898315,-1.3551691174507141 4.319730997085571,-0.20143985748291016 m-11.300448179244995,4.541122913360596 l8.531174063682556,1.5979398787021637 8.473154306411743,2.7444010972976685 m-23.34967613220215,-8.475967049598694 l-0.8660716563463211,0.24707568809390068 -0.49268726259469986,0.9570836275815964 l0.611819364130497,0.3026055544614792 m5.076432228088379,-3.1461703777313232 l-0.9608932584524155,0.7198524475097656 1.527978926897049,1.6084915399551392 m74.67173250235646,-5.563314678865936 l-4.04545396566391,-0.15319337137043476 -2.9755526781082153,0.5619113519787788 l-4.447781145572662,2.0131435990333557 -3.703804612159729,3.38160902261734 l-2.2621287405490875,4.285043179988861 -0.9097392112016678,3.9325708150863647 l-0.003944211057387292,5.435736775398254 1.0356803983449936,3.2059499621391296 l2.541545331478119,3.078072965145111 2.5918102264404297,1.5643705427646637 l2.142306864261627,0.8041606098413467 6.412729620933533,0.4738498851656914 l7.45698094367981,-3.0385299396584742e-05 3.7498080730438232,-0.8783009648323059 l3.794437050819397,-1.5941454470157623 4.0894341468811035,-3.5529622435569763 l1.4933834969997406,-2.251175045967102 1.1732443422079086,-3.631364405155182 l-8.691120456205681e-05,-5.175444483757019 -1.7250935733318329,-3.299669027328491 l-3.70665967464447,-4.439828991889954 -4.777102470397949,-2.6608633995056152 l-4.554602801799774,-1.3190078735351562 -3.7718647718429565,0.0001329348287981702 l-2.5637203454971313,0.9884383529424667 m-10.108743906021118,5.343371033668518 l0.13113496825098991,-0.4590386152267456 0.5976437404751778,-0.6191480904817581 l3.5681328177452087,-3.393492102622986 2.194015085697174,-1.0466723889112473 l2.0279334485530853,-0.4841366410255432 2.2703689336776733,0.00028501837732619606 l4.359754323959351,1.9798707962036133 1.1016421020030975,1.3566263020038605 l0.07635930553078651,1.378147453069687 -0.017892814939841628,0.15300460159778595 l0.17628319561481476,-0.813310518860817 1.3488627970218658,-2.0736074447631836 l5.678096413612366,-6.153099536895752 6.4974236488342285,-3.7474650144577026 l-1.95290207862854,8.176384568214417 -0.5240200832486153,5.806537866592407 m-17.702068090438843,10.803474187850952 l-0.9197627753019333,-1.2197445333003998 m8.277299404144287,0.5310854688286781 l0.8727988600730896,0.0002638709338498302 m-8.080587387084961,3.0666756629943848 l-8.450589776039124,0.8271440863609314 -12.279531955718994,-0.05091030150651932 m15.860954523086548,1.2705650925636292 l-9.555180668830872,2.3843447864055634 -3.693414330482483,0.18087277188897133 l-1.1638563126325607,0.5050048232078552 m24.212665557861328,-1.9473841786384583 l1.1680129915475845,0.0764110404998064 4.740972518920898,-1.3383354246616364 l6.14443302154541,-0.6709060072898865 5.231926441192627,-1.6569207608699799 m-15.668501853942871,4.072073400020599 l14.82564091682434,1.129700243473053 5.684677958488464,1.6550052165985107 l2.273271530866623,0.90371273458004 m-23.41097593307495,-4.01295006275177 l-2.071172744035721,0.10321666486561298 -1.6205567121505737,1.7926299571990967 l-0.8357410132884979,2.1231596171855927 m90.4149372332705,-31.953718739741817 l-3.8937127590179443,-0.09308391250669956 -3.6613431572914124,1.074952557682991 l-4.843720495700836,2.9983222484588623 -1.841437816619873,2.0207738876342773 l-1.5015269815921783,2.878367602825165 -1.567833125591278,5.78991174697876 l-1.083257868885994,8.86434555053711 0.21076049655675888,2.837471663951874 l1.3797739148139954,1.9408546388149261 2.696921229362488,1.4029721915721893 l7.111380100250244,1.4985987544059753 8.292148113250732,0.27791792526841164 l7.337288856506348,-1.2698444724082947 2.180425375699997,-0.9233206510543823 l1.7583830654621124,-1.279994249343872 1.9854947924613953,-2.56923645734787 l2.4761442840099335,-4.455203115940094 0.42754489928483963,-2.075130343437195 l6.461797852352902e-06,-3.414200246334076 -0.6919921934604645,-3.2257208228111267 l-0.7291961461305618,-1.5717794001102448 -3.281354308128357,-3.109841048717499 l-3.8241177797317505,-2.472473680973053 m7.7815306186676025,0.8734577894210815 l-1.0429251939058304,-1.5417125821113586 -2.4764078855514526,-2.721332311630249 l-1.408885270357132,-0.5092453956604004 -3.3653566241264343,0.00021771251340396702 l-3.051403760910034,0.6908983737230301 -2.767133414745331,1.5966589748859406 l-0.12077860534191132,0.3753530979156494 m-23.219187259674072,8.902546167373657 l-0.6340285390615463,-1.8477703630924225 -1.2767435610294342,-1.270991563796997 l-5.760678052902222,-2.218160331249237 -3.7693223357200623,-0.14899631962180138 l0.332552045583725,5.909576416015625 1.7871810495853424,3.8319316506385803 l2.946842312812805,4.449597001075745 2.032487541437149,3.140650987625122 l2.132796347141266,2.533774673938751 2.1491488814353943,1.2105198204517365 l2.6612868905067444,-0.015663314843550324 m29.18625831604004,-8.926389217376709 l-0.0008553519728593528,-0.00013172942090022843 m-9.799121618270874,3.847459852695465 l0.8568320423364639,-0.019283589208498597 2.001394033432007,-0.4620854929089546 m-10.43691635131836,-7.122845649719238 l-3.2306742668151855,-6.759796633559745e-05 -6.991481781005859,2.6378336548805237 m10.137189626693726,-0.6251830607652664 l-1.6336992383003235,0.5325191095471382 -8.588131666183472,6.374032497406006 l-2.2013597190380096,2.428722381591797 m9.8332279920578,-6.66079044342041 l-5.098901987075806,3.7994250655174255 -4.5616015791893005,5.391178131103516 m17.178020477294922,-10.134704113006592 l10.699326992034912,0.31087199226021767 4.460367560386658,-0.8051890879869461 l0.6560284644365311,-0.4954183101654053 m-16.60451889038086,4.03893768787384 l10.302538871765137,1.4501458406448364 1.9047962129116058,0.70841945707798 m61.250972270572674,-20.444261288521375 l-4.117169082164764,-0.04351457115262747 -3.8162761926651,0.7486577332019806 l-1.962144523859024,1.0560376197099686 -3.229342997074127,2.850591540336609 l-4.392252862453461,6.228057146072388 -1.8616001307964325,3.2785046100616455 l-1.0580413788557053,3.8463804125785828 -0.02178418217226863,2.7964061498641968 l2.87299245595932,5.434508323669434 4.3069252371788025,2.765112817287445 l2.6695746183395386,0.7575706392526627 5.737999081611633,0.11974523775279522 l3.7433281540870667,-0.7194892317056656 2.5265905261039734,-0.9678442031145096 l6.024689078330994,-3.328762650489807 2.5749486684799194,-2.2944584488868713 l1.6008257865905762,-2.7844393253326416 1.457851082086563,-3.837628662586212 l0.7747595757246017,-3.7225383520126343 -0.006188960978761315,-2.89658784866333 l-2.1858826279640198,-4.21869158744812 -2.3563429713249207,-2.6304808259010315 l-2.6697728037834167,-1.7161214351654053 -6.7127299308776855,-0.9924563020467758 l-0.9607429802417755,0.0006149782711872831 m7.222310304641724,1.3033854961395264 l1.7921796441078186,-0.7119255512952805 3.115275204181671,-0.6121658906340599 l4.1900646686553955,-0.10831156745553017 -0.00024295099137816578,4.835895597934723 l-1.7839150130748749,1.3811853528022766 -2.410478889942169,0.48773523420095444 m-25.33639907836914,-4.39871072769165 l0.6589580327272415,-0.996171236038208 -0.5638943612575531,-2.233736664056778 l-2.336330860853195,-2.8242403268814087 -1.9883687794208527,-1.482253223657608 l-1.7437148094177246,-1.1172598600387573 -0.3649846464395523,0.630255863070488 l0.698508620262146,2.194029986858368 2.5128617882728577,5.920373201370239 l0.6259825080633163,1.7774373292922974 m13.039114475250244,18.279420137405396 l-1.0986512154340744,2.6774898171424866 -1.51956707239151,0.7979931682348251 m2.0613695681095123,0.8796612173318863 l-0.28245709836483,2.7387699484825134 0.5502937734127045,0.7184942811727524 l0.7530836760997772,-2.349637448787689 -0.7779207825660706,-2.4515891075134277 m-10.84470510482788,-5.307386517524719 l-12.463828325271606,2.0683735609054565 m14.308873414993286,1.5543632209300995 l-9.39099371433258,2.3429356515407562 -2.449074387550354,1.1894774436950684 m30.175762176513672,-7.7632856369018555 l-0.24748634546995163,-0.6086718663573265 0.8554226160049438,-0.8268282562494278 l21.29335880279541,-6.930500268936157 m-21.280012130737305,8.42770516872406 l0.904976949095726,-0.0649357121437788 12.434091567993164,-2.377837747335434 l10.572665929794312,-2.559922933578491 m-39.1470742225647,-7.543336749076843 l-1.216803565621376,0.30139176174998283 1.0772580653429031,0.08879886940121651 m94.27270915486588,-9.009373396074807 l-4.255047142505646,-0.16288325190544128 -4.343909025192261,0.8734381943941116 l-2.6164236664772034,1.6137661039829254 -4.782731831073761,4.825303256511688 l-1.7746298015117645,3.255477249622345 0.00017700333046377636,7.170728445053101 l1.9658923149108887,2.9183104634284973 3.085070848464966,1.694938987493515 l1.675083488225937,0.7306663691997528 -0.49197234213352203,0.42122285813093185 l1.1759212613105774,2.1981054544448853 11.551885604858398,5.88397741317749 l2.1572494506835938,-0.0004096917837159708 3.997487425804138,-1.3750723004341125 l3.8753855228424072,-2.196429967880249 5.29521107673645,-1.365092396736145 l2.853507399559021,-1.6392026841640472 0.299618486315012,-1.4208769798278809 l-0.5126786604523659,-2.2965797781944275 -2.530984878540039,-4.6613770723342896 l-2.2262631356716156,-2.9300469160079956 0.02370854141190648,-5.930312275886536 l1.1731064319610596,-5.447198748588562 -4.220066330162808e-05,-4.3816909193992615 l-1.4810405671596527,-2.02616348862648 -1.5562376379966736,-0.3877922520041466 l-6.963849067687988,2.0768028497695923 -5.805718898773193,2.848421037197113 m-14.256134033203125,10.990076065063477 l-1.0415264964103699,-0.2281768061220646 -2.046748697757721,0.4835917800664902 l-1.8044741451740265,1.0672162473201752 1.2950707972049713,1.452963501214981 l4.051414132118225,-0.5533810704946518 -0.23849895223975182,-1.0829338431358337 l-2.2486041486263275,-1.1373277753591537 m21.826159954071045,-1.4616532623767853 l-1.5372075140476227,0.00018921116861747578 -1.6355188190937042,0.6524426490068436 l-1.2990519404411316,1.1064638197422028 -1.1599720269441605,1.8582838773727417 l0.06472832523286343,1.164769008755684 0.5245838686823845,0.8444017916917801 l1.0116036236286163,0.3450964018702507 9.92084264755249,-1.2895983457565308 l2.445865720510483,-1.35732039809227 m-3.383762240409851,-1.0895437747240067 l0.0008007284486666322,0.00011739813999156468 m-19.19236421585083,-7.499798536300659 l2.257193773984909,2.5750523805618286 0.2301199734210968,0.23063862696290016 m5.356016755104065,8.492751121520996 l6.717305779457092,0.0001263337708223844 13.147534132003784,-1.2398429214954376 m-16.045048236846924,1.7960639297962189 l8.645941019058228,2.916366457939148 1.7511914670467377,1.2514160573482513 m-14.80138897895813,-9.033225178718567 l-4.696072638034821,-0.0003122511043329723 -17.627559900283813,-0.12956748716533184 m12.09062933921814,0.3653109073638916 l-5.9494733810424805,-0.5207301303744316 -3.753874897956848,0.33158447593450546 l-3.1391000747680664,0.9349846839904785 -2.361692637205124,1.6438756883144379 \" fill=\"none\" stroke=\"black\" stroke-width=\"1\"/></svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stroke_list = []\n",
    "for i in range(10):\n",
    "  stroke_list.append([decode(z, draw_mode=False, temperature=0.1*i+0.1), [0, i]])\n",
    "stroke_grid = make_grid_svg(stroke_list)\n",
    "draw_strokes(stroke_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型加载成功: ../ResNet/res18-30-cosine/checkpoint_epoch_30.pth\n",
      "模型类型: resnet18, 类别数: 345\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import json\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "from Model.nets import resnet34, resnet18\n",
    "from Model.nets import convnet\n",
    "\n",
    "def load_model(model_path, model_type='resnet18', num_classes=345, in_channels=3, image_size=224, device='cpu'):\n",
    "    \"\"\"\n",
    "    加载训练好的模型\n",
    "    \"\"\"\n",
    "    # 根据模型类型创建模型实例\n",
    "    if model_type == 'resnet34':\n",
    "        model = resnet34(num_classes, pretrained=False, in_channels=in_channels, image_size=image_size)\n",
    "    elif model_type == 'resnet18':\n",
    "        model = resnet18(num_classes, pretrained=False, in_channels=in_channels, image_size=image_size)\n",
    "    elif model_type == 'convnet':\n",
    "        model = convnet(num_classes)\n",
    "    else:\n",
    "        raise ValueError(f\"不支持的模型类型: {model_type}\")\n",
    "    \n",
    "    # 加载模型权重\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    \n",
    "    # 检查是否是完整checkpoint还是只有模型权重\n",
    "    if 'model_state_dict' in checkpoint:\n",
    "        model_weights = checkpoint['model_state_dict']\n",
    "    else:\n",
    "        model_weights = checkpoint\n",
    "    \n",
    "    # 加载权重（处理可能的DataParallel前缀）\n",
    "    if list(model_weights.keys())[0].startswith('module.'):\n",
    "        # 如果权重有'module.'前缀，但模型不是DataParallel，需要移除前缀\n",
    "        from collections import OrderedDict\n",
    "        new_state_dict = OrderedDict()\n",
    "        for k, v in model_weights.items():\n",
    "            name = k[7:] if k.startswith('module.') else k  # 移除'module.'前缀\n",
    "            new_state_dict[name] = v\n",
    "        model_weights = new_state_dict\n",
    "    \n",
    "    model.load_state_dict(model_weights)\n",
    "    model = model.to(device)\n",
    "    model.eval()  # 设置为评估模式\n",
    "    \n",
    "    print(f\"模型加载成功: {model_path}\")\n",
    "    print(f\"模型类型: {model_type}, 类别数: {num_classes}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "model_path = '../ResNet/res18-30-cosine/checkpoint_epoch_30.pth'\n",
    "resnet = load_model(model_path)\n",
    "# print(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from Utils import draw_three, off2abs\n",
    "transform_list = [\n",
    "        transforms.ToTensor(), transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])]\n",
    "trans = transforms.Compose(transform_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# n_img = torch.unsqueeze(trans(img), dim=0)\n",
    "# res = net(n_img)\n",
    "# strokes = np.load('/inspire/hdd/project/wuliqifa/yanjunchi-24040/hang/recon/QuickDraw414k/coordinate_files/test/cake/cake_20.npy',encoding='latin1', allow_pickle=True)\n",
    "# seq = strokes[:, 0:3]\n",
    "# seq = seq.astype('float32')\n",
    "# print(seq.shape)\n",
    "print(strokes)\n",
    "strokes_n = convert_seq(strokes)\n",
    "# print(strokes_n)\n",
    "test(strokes_n, resnet)\n",
    "# print(res)\n",
    "# pred = res.data.max(1)[1].item()\n",
    "# print(pred, res[0][pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_img = torch.unsqueeze(trans(img), dim=0)\n",
    "res = net(n_img)\n",
    "seq = np.load('/inspire/hdd/project/wuliqifa/yanjunchi-24040/hang/recon/QuickDraw414k/coordinate_files/test/cake/cake_20.npy',encoding='latin1', allow_pickle=True)\n",
    "seq = seq[:, 0:3]\n",
    "seq = seq.astype('float32')\n",
    "print(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.772 0.82\n"
     ]
    }
   ],
   "source": [
    "def get_next(loader, batch_idx, bs):\n",
    "    batch = []\n",
    "    for idx in range(bs):\n",
    "      i = bs * batch_idx + idx\n",
    "      data = loader.strokes[i]\n",
    "      data_copy = np.copy(data)\n",
    "      batch.append(data_copy)\n",
    "    return batch\n",
    "acc_top1 = 0\n",
    "acc_top5 = 0\n",
    "cid = 67\n",
    "trails = 50\n",
    "for _ in range(5):\n",
    "    for batch_idx in range(trails):\n",
    "        stroke = get_next(test_set, batch_idx, 4)\n",
    "        z = encode(stroke[0])\n",
    "        seq_e = decode(z, temperature=0.1, class_id=54, draw_mode=False)\n",
    "        seq_en = convert_seq(seq_e)\n",
    "        ids, prob = test(seq_en, resnet)\n",
    "        # print(ids)\n",
    "        if ids[0] == cid:\n",
    "            acc_top1 += 1\n",
    "        if cid in ids:\n",
    "            acc_top5 += 1\n",
    "trails *= 5\n",
    "acc_top1 /= (trails)\n",
    "acc_top5 /= (trails)\n",
    "print(acc_top1, acc_top5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9989953114534494"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 75\n",
    "ac = 75.15\n",
    "at = (a - 1 + ac) / (2 * ac - 1)\n",
    "at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.59 0.74 [0.16, 0.12, 0.11, 0.07, 0.13]\n"
     ]
    }
   ],
   "source": [
    "acc_top1 = 0\n",
    "acc_top5 = 0\n",
    "cid = 67\n",
    "trails = 100\n",
    "gt_ids = [52, 67, 261, 54, 119]\n",
    "accs = [0, 0, 0, 0, 0]\n",
    "for batch_idx in range(trails):\n",
    "    seq_e = decode(temperature=0.1, class_id=67, draw_mode=False)\n",
    "    seq_en = convert_seq(seq_e)\n",
    "    ids, prob = test(seq_en, resnet)\n",
    "    if ids[0] in gt_ids:\n",
    "        acc_top1 += 1\n",
    "    for id in ids:\n",
    "        if id in gt_ids:\n",
    "            acc_top5 += 1\n",
    "            break\n",
    "    for i in range(len(gt_ids)):\n",
    "        if ids[0] == gt_ids[i]:\n",
    "            accs[i] += 1\n",
    "            break\n",
    "acc_top1 /= (trails)\n",
    "acc_top5 /= (trails)\n",
    "accs = [x / trails for x in accs]\n",
    "print(acc_top1, acc_top5, accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def stroke3_delta_to_abs_points(stroke3_delta: np.ndarray, reset_on_penup: bool = False) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    stroke3_delta: [N,3] where each row is [dx, dy, pen_up]\n",
    "    返回 absolute points: [N,2]\n",
    "    reset_on_penup:\n",
    "      - False: 全程累加（更常见）\n",
    "      - True: 每次 pen_up=1 后，下一个点从 (0,0) 重新开始累加（更像“分段独立”）\n",
    "    \"\"\"\n",
    "    s = np.asarray(stroke3_delta)\n",
    "    assert s.ndim == 2 and s.shape[1] >= 2\n",
    "    dxdy = s[:, :2].astype(np.float64)\n",
    "\n",
    "    abs_pts = np.zeros((len(dxdy), 2), dtype=np.float64)\n",
    "    x, y = 0.0, 0.0\n",
    "\n",
    "    if s.shape[1] >= 3:\n",
    "        pen = s[:, 2].astype(np.int32)\n",
    "    else:\n",
    "        pen = np.zeros((len(dxdy),), dtype=np.int32)\n",
    "\n",
    "    for i in range(len(dxdy)):\n",
    "        x += dxdy[i, 0]\n",
    "        y += dxdy[i, 1]\n",
    "        abs_pts[i] = (x, y)\n",
    "\n",
    "        if reset_on_penup and pen[i] == 1:\n",
    "            x, y = 0.0, 0.0\n",
    "\n",
    "    return abs_pts\n",
    "\n",
    "def _resample_by_arclength(points: np.ndarray, m: int) -> np.ndarray:\n",
    "    points = np.asarray(points, dtype=np.float64)\n",
    "    n = len(points)\n",
    "    if n == 0:\n",
    "        return np.zeros((m, 2), dtype=np.float64)\n",
    "    if n == 1:\n",
    "        return np.repeat(points, m, axis=0)\n",
    "\n",
    "    seg = points[1:] - points[:-1]\n",
    "    seg_len = np.linalg.norm(seg, axis=1)\n",
    "    cum = np.concatenate([[0.0], np.cumsum(seg_len)])\n",
    "    total = cum[-1]\n",
    "\n",
    "    if total < 1e-12:\n",
    "        return np.repeat(points[:1], m, axis=0)\n",
    "\n",
    "    target = np.linspace(0.0, total, m)\n",
    "    out = np.zeros((m, 2), dtype=np.float64)\n",
    "\n",
    "    j = 0\n",
    "    for i, t in enumerate(target):\n",
    "        while j < len(cum) - 1 and cum[j + 1] < t:\n",
    "            j += 1\n",
    "        if j == len(cum) - 1:\n",
    "            out[i] = points[-1]\n",
    "        else:\n",
    "            t0, t1 = cum[j], cum[j + 1]\n",
    "            alpha = 0.0 if (t1 - t0) < 1e-12 else (t - t0) / (t1 - t0)\n",
    "            out[i] = (1 - alpha) * points[j] + alpha * points[j + 1]\n",
    "    return out\n",
    "\n",
    "def stroke_l2_distance_delta(\n",
    "    stroke_a_delta: np.ndarray,\n",
    "    stroke_b_delta: np.ndarray,\n",
    "    num_samples: int = 128,\n",
    "    align: str = \"center\",   # \"none\" | \"start\" | \"center\"\n",
    "    reset_on_penup: bool = False,\n",
    "    return_all: bool = False,\n",
    "):\n",
    "    \"\"\"\n",
    "    输入：两个 stroke-3 delta（[dx,dy,pen_up]）\n",
    "    输出：mean_l2 / rmse / max_l2\n",
    "    \"\"\"\n",
    "    pa = stroke3_delta_to_abs_points(stroke_a_delta, reset_on_penup=reset_on_penup)\n",
    "    pb = stroke3_delta_to_abs_points(stroke_b_delta, reset_on_penup=reset_on_penup)\n",
    "\n",
    "    ra = _resample_by_arclength(pa, num_samples)\n",
    "    rb = _resample_by_arclength(pb, num_samples)\n",
    "\n",
    "    if align == \"start\":\n",
    "        ra = ra - ra[:1]\n",
    "        rb = rb - rb[:1]\n",
    "    elif align == \"center\":\n",
    "        ra = ra - ra.mean(axis=0, keepdims=True)\n",
    "        rb = rb - rb.mean(axis=0, keepdims=True)\n",
    "    elif align == \"none\":\n",
    "        pass\n",
    "    else:\n",
    "        raise ValueError(\"align must be one of: none/start/center\")\n",
    "\n",
    "    d = np.linalg.norm(ra - rb, axis=1)\n",
    "    mean_l2 = float(d.mean())\n",
    "    rmse = float(np.sqrt((d ** 2).mean()))\n",
    "    max_l2 = float(d.max())\n",
    "\n",
    "    if return_all:\n",
    "        return {\"mean_l2\": mean_l2, \"rmse\": rmse, \"max_l2\": max_l2, \"ra\": ra, \"rb\": rb, \"per_point\": d}\n",
    "    return {\"mean_l2\": mean_l2, \"rmse\": rmse, \"max_l2\": max_l2}\n",
    "\n",
    "# print(stroke.shape, strokes.shape)\n",
    "import numpy as np\n",
    "\n",
    "# 初始化列表存储所有指标\n",
    "mean_l2_list = []\n",
    "rmse_list = []\n",
    "max_l2_list = []\n",
    "\n",
    "for i in range(100):\n",
    "    stroke = get_next(test_set, i, 4)[0]\n",
    "    z = encode(stroke)\n",
    "    seq_e = decode(z, temperature=0.1, class_id=67, draw_mode=False)\n",
    "    seq_en = convert_seq(seq_e)\n",
    "    \n",
    "    metrics = stroke_l2_distance_abs(stroke, seq_e, num_samples=128, align=\"center\")\n",
    "    print(f\"第{i+1}次测试: mean_l2={metrics['mean_l2']:.4f}, rmse={metrics['rmse']:.4f}, max_l2={metrics['max_l2']:.4f}\")\n",
    "    \n",
    "    # 收集指标\n",
    "    mean_l2_list.append(metrics['mean_l2'])\n",
    "    rmse_list.append(metrics['rmse'])\n",
    "    max_l2_list.append(metrics['max_l2'])\n",
    "\n",
    "# 转换为numpy数组以便计算统计量\n",
    "mean_l2_arr = np.array(mean_l2_list)\n",
    "rmse_arr = np.array(rmse_list)\n",
    "max_l2_arr = np.array(max_l2_list)\n",
    "\n",
    "# 计算统计量\n",
    "avg_metrics = {\n",
    "    'mean_l2': {\n",
    "        'mean': np.mean(mean_l2_arr),\n",
    "        'std': np.std(mean_l2_arr),\n",
    "        'min': np.min(mean_l2_arr),\n",
    "        'max': np.max(mean_l2_arr)\n",
    "    },\n",
    "    'rmse': {\n",
    "        'mean': np.mean(rmse_arr),\n",
    "        'std': np.std(rmse_arr),\n",
    "        'min': np.min(rmse_arr),\n",
    "        'max': np.max(rmse_arr)\n",
    "    },\n",
    "    'max_l2': {\n",
    "        'mean': np.mean(max_l2_arr),\n",
    "        'std': np.std(max_l2_arr),\n",
    "        'min': np.min(max_l2_arr),\n",
    "        'max': np.max(max_l2_arr)\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"50次测试详细统计:\")\n",
    "print(\"-\"*60)\n",
    "print(f\"mean_l2 - 平均值: {avg_metrics['mean_l2']['mean']:.6f}, 标准差: {avg_metrics['mean_l2']['std']:.6f}\")\n",
    "print(f\"        最小值: {avg_metrics['mean_l2']['min']:.6f}, 最大值: {avg_metrics['mean_l2']['max']:.6f}\")\n",
    "print(f\"rmse    - 平均值: {avg_metrics['rmse']['mean']:.6f}, 标准差: {avg_metrics['rmse']['std']:.6f}\")\n",
    "print(f\"        最小值: {avg_metrics['rmse']['min']:.6f}, 最大值: {avg_metrics['rmse']['max']:.6f}\")\n",
    "print(f\"max_l2  - 平均值: {avg_metrics['max_l2']['mean']:.6f}, 标准差: {avg_metrics['max_l2']['std']:.6f}\")\n",
    "print(f\"        最小值: {avg_metrics['max_l2']['min']:.6f}, 最大值: {avg_metrics['max_l2']['max']:.6f}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def dtw_distance(points_a: np.ndarray, points_b: np.ndarray) -> float:\n",
    "    a = np.asarray(points_a, dtype=np.float64)\n",
    "    b = np.asarray(points_b, dtype=np.float64)\n",
    "    n, m = len(a), len(b)\n",
    "    if n == 0 or m == 0:\n",
    "        return float(\"inf\")\n",
    "\n",
    "    dp = np.full((n + 1, m + 1), np.inf, dtype=np.float64)\n",
    "    dp[0, 0] = 0.0\n",
    "\n",
    "    for i in range(1, n + 1):\n",
    "        for j in range(1, m + 1):\n",
    "            cost = np.linalg.norm(a[i - 1] - b[j - 1])\n",
    "            dp[i, j] = cost + min(dp[i - 1, j], dp[i, j - 1], dp[i - 1, j - 1])\n",
    "\n",
    "    return float(dp[n, m] / (n + m))  # 归一化，便于比较\n",
    "\n",
    "def stroke_dtw_distance_delta(\n",
    "    stroke_a_delta: np.ndarray,\n",
    "    stroke_b_delta: np.ndarray,\n",
    "    num_samples: int = 128,\n",
    "    align: str = \"center\",\n",
    "    reset_on_penup: bool = False,\n",
    ") -> float:\n",
    "    pa = stroke3_delta_to_abs_points(stroke_a_delta, reset_on_penup=reset_on_penup)\n",
    "    pb = stroke3_delta_to_abs_points(stroke_b_delta, reset_on_penup=reset_on_penup)\n",
    "\n",
    "    ra = _resample_by_arclength(pa, num_samples)\n",
    "    rb = _resample_by_arclength(pb, num_samples)\n",
    "\n",
    "    if align == \"start\":\n",
    "        ra = ra - ra[:1]\n",
    "        rb = rb - rb[:1]\n",
    "    elif align == \"center\":\n",
    "        ra = ra - ra.mean(axis=0, keepdims=True)\n",
    "        rb = rb - rb.mean(axis=0, keepdims=True)\n",
    "    elif align == \"none\":\n",
    "        pass\n",
    "    else:\n",
    "        raise ValueError(\"align must be one of: none/start/center\")\n",
    "\n",
    "    return dtw_distance(ra, rb)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# 初始化列表存储所有指标\n",
    "mean_l2_list = []\n",
    "\n",
    "for i in range(100):\n",
    "    stroke = get_next(test_set, i, 4)[0]\n",
    "    z = encode(stroke)\n",
    "    seq_e = decode(z, temperature=0.1, class_id=67, draw_mode=False)\n",
    "    seq_en = convert_seq(seq_e)\n",
    "    \n",
    "    metrics = stroke_dtw_distance_delta(stroke, seq_e, num_samples=128, align=\"center\")\n",
    "    print(f\"第{i+1}次测试: mean_l2={metrics:.4f}\")\n",
    "    \n",
    "    # 收集指标\n",
    "    mean_l2_list.append(metrics)\n",
    "\n",
    "# 转换为numpy数组以便计算统计量\n",
    "mean_l2_arr = np.array(mean_l2_list)\n",
    "rmse_arr = np.array(rmse_list)\n",
    "max_l2_arr = np.array(max_l2_list)\n",
    "\n",
    "# 计算统计量\n",
    "avg_metrics = {\n",
    "    'mean_l2': {\n",
    "        'mean': np.mean(mean_l2_arr),\n",
    "        'std': np.std(mean_l2_arr),\n",
    "        'min': np.min(mean_l2_arr),\n",
    "        'max': np.max(mean_l2_arr)\n",
    "    },\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"50次测试详细统计:\")\n",
    "print(\"-\"*60)\n",
    "print(f\"mean_l2 - 平均值: {avg_metrics['mean_l2']['mean']:.6f}, 标准差: {avg_metrics['mean_l2']['std']:.6f}\")\n",
    "print(f\"        最小值: {avg_metrics['mean_l2']['min']:.6f}, 最大值: {avg_metrics['mean_l2']['max']:.6f}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def chamfer_distance(points_a: np.ndarray, points_b: np.ndarray) -> float:\n",
    "    a = np.asarray(points_a, dtype=np.float64)\n",
    "    b = np.asarray(points_b, dtype=np.float64)\n",
    "    if len(a) == 0 or len(b) == 0:\n",
    "        return float(\"inf\")\n",
    "\n",
    "    diff = a[:, None, :] - b[None, :, :]\n",
    "    dist2 = np.sum(diff * diff, axis=2)  # [N,M]\n",
    "    a2b = np.min(dist2, axis=1).mean()\n",
    "    b2a = np.min(dist2, axis=0).mean()\n",
    "    return float(a2b + b2a)\n",
    "\n",
    "def stroke_chamfer_distance_delta(\n",
    "    stroke_a_delta: np.ndarray,\n",
    "    stroke_b_delta: np.ndarray,\n",
    "    num_samples: int = 128,\n",
    "    align: str = \"center\",\n",
    "    reset_on_penup: bool = False,\n",
    ") -> float:\n",
    "    pa = stroke3_delta_to_abs_points(stroke_a_delta, reset_on_penup=reset_on_penup)\n",
    "    pb = stroke3_delta_to_abs_points(stroke_b_delta, reset_on_penup=reset_on_penup)\n",
    "\n",
    "    ra = _resample_by_arclength(pa, num_samples)\n",
    "    rb = _resample_by_arclength(pb, num_samples)\n",
    "\n",
    "    if align == \"start\":\n",
    "        ra = ra - ra[:1]\n",
    "        rb = rb - rb[:1]\n",
    "    elif align == \"center\":\n",
    "        ra = ra - ra.mean(axis=0, keepdims=True)\n",
    "        rb = rb - rb.mean(axis=0, keepdims=True)\n",
    "    elif align == \"none\":\n",
    "        pass\n",
    "    else:\n",
    "        raise ValueError(\"align must be one of: none/start/center\")\n",
    "\n",
    "    return chamfer_distance(ra, rb)\n",
    "mean_l2_list = []\n",
    "\n",
    "for t in range(10):\n",
    "    for i in range(50):\n",
    "        stroke = get_next(test_set, i, 4)[0]\n",
    "        z = encode(stroke)\n",
    "        seq_e = decode(z, temperature=0.1+t*0.1, class_id=67, draw_mode=False)\n",
    "        seq_en = convert_seq(seq_e)\n",
    "\n",
    "        metrics = stroke_chamfer_distance_delta(stroke, seq_e, num_samples=128, align=\"center\")\n",
    "        # print(f\"第{i+1}次测试: mean_l2={metrics:.4f}\")\n",
    "\n",
    "        # 收集指标\n",
    "        mean_l2_list.append(metrics)\n",
    "\n",
    "    # 转换为numpy数组以便计算统计量\n",
    "    mean_l2_arr = np.array(mean_l2_list)\n",
    "    rmse_arr = np.array(rmse_list)\n",
    "    max_l2_arr = np.array(max_l2_list)\n",
    "\n",
    "    # 计算统计量\n",
    "    avg_metrics = {\n",
    "        'mean_l2': {\n",
    "            'mean': np.mean(mean_l2_arr),\n",
    "            'std': np.std(mean_l2_arr),\n",
    "            'min': np.min(mean_l2_arr),\n",
    "            'max': np.max(mean_l2_arr)\n",
    "        },\n",
    "    }\n",
    "    print(f'温度: {0.1+t*0.1}')\n",
    "    print(f\"平均值: {avg_metrics['mean_l2']['mean']:.6f}, 标准差: {avg_metrics['mean_l2']['std']:.6f}\")\n",
    "    print(f\"最小值: {avg_metrics['mean_l2']['min']:.6f}, 最大值: {avg_metrics['mean_l2']['max']:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def diversity_fidelity_for_one_input(\n",
    "    stroke_delta,\n",
    "    encode_fn,\n",
    "    decode_fn,\n",
    "    stroke_distance_fn,     # e.g. stroke_chamfer_distance_delta\n",
    "    class_id,\n",
    "    num_samples=8,\n",
    "    temperatures=None,      # list[float] or None -> 全用同一个 0.2\n",
    "    num_resample_points=128,\n",
    "    align=\"center\",\n",
    "    reset_on_penup=False,\n",
    "    rng_seed=0,\n",
    "    decode_kwargs=None,\n",
    "):\n",
    "    if decode_kwargs is None:\n",
    "        decode_kwargs = {}\n",
    "\n",
    "    # 1) 得到基准 latent\n",
    "    z0 = np.asarray(encode_fn(stroke_delta)).reshape(-1)\n",
    "\n",
    "    # 2) 采样生成多个重建\n",
    "    if temperatures is None:\n",
    "        temperatures = [0.2] * num_samples\n",
    "    else:\n",
    "        assert len(temperatures) == num_samples\n",
    "\n",
    "    # 让每次 decode 有可控随机性（如果你的 decode 内部用 np.random）\n",
    "    rng = np.random.default_rng(rng_seed)\n",
    "\n",
    "    gens = []\n",
    "    fidelities = []\n",
    "\n",
    "    for k in range(num_samples):\n",
    "        # 可选：如果 decode 里依赖 np.random，全局 seed 可以这样做（粗暴但常用）\n",
    "        np.random.seed(int(rng.integers(0, 2**31-1)))\n",
    "\n",
    "        seq_k = decode_fn(\n",
    "            z0,\n",
    "            temperature=float(temperatures[k]),\n",
    "            class_id=int(class_id),\n",
    "            draw_mode=False,\n",
    "            **decode_kwargs,\n",
    "        )\n",
    "        gens.append(seq_k)\n",
    "\n",
    "        fid = stroke_distance_fn(\n",
    "            stroke_delta, seq_k,\n",
    "            num_samples=num_resample_points,\n",
    "            align=align,\n",
    "            reset_on_penup=reset_on_penup\n",
    "        )\n",
    "        # 兼容你 distance_fn 返回 dict 或 float\n",
    "        if isinstance(fid, dict):\n",
    "            # chamfer那版如果你返回 float 就不会走这里\n",
    "            fid_val = float(fid.get(\"mean_l2\", fid.get(\"rmse\", list(fid.values())[0])))\n",
    "        else:\n",
    "            fid_val = float(fid)\n",
    "        fidelities.append(fid_val)\n",
    "\n",
    "    # 3) diversity：样本间两两平均距离\n",
    "    pair_dists = []\n",
    "    for i in range(num_samples):\n",
    "        for j in range(i + 1, num_samples):\n",
    "            dij = stroke_distance_fn(\n",
    "                gens[i], gens[j],\n",
    "                num_samples=num_resample_points,\n",
    "                align=align,\n",
    "                reset_on_penup=reset_on_penup\n",
    "            )\n",
    "            pair_dists.append(float(dij) if not isinstance(dij, dict) else float(list(dij.values())[0]))\n",
    "\n",
    "    diversity = float(np.mean(pair_dists)) if pair_dists else 0.0\n",
    "    fidelity = float(np.mean(fidelities))\n",
    "\n",
    "    return {\n",
    "        \"diversity\": diversity,\n",
    "        \"fidelity\": fidelity,\n",
    "        \"fidelities\": np.array(fidelities, dtype=np.float64),\n",
    "        \"pairwise\": np.array(pair_dists, dtype=np.float64),\n",
    "        \"gens\": gens,\n",
    "        \"z0\": z0,\n",
    "    }\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def diversity_fidelity_scatter(\n",
    "    strokes_list,           # list of stroke-3 delta\n",
    "    encode_fn,\n",
    "    decode_fn,\n",
    "    stroke_distance_fn,     # e.g. stroke_chamfer_distance_delta\n",
    "    class_id,\n",
    "    num_samples_per_input=8,\n",
    "    temperature_base=0.1,\n",
    "    temperature_step=0.05,\n",
    "    num_resample_points=128,\n",
    "    align=\"center\",\n",
    "    reset_on_penup=False,\n",
    "    decode_kwargs=None,\n",
    "):\n",
    "    if decode_kwargs is None:\n",
    "        decode_kwargs = {}\n",
    "\n",
    "    xs = []\n",
    "    ys = []\n",
    "    per_item = []\n",
    "\n",
    "    for idx, stroke in enumerate(strokes_list):\n",
    "        temps = [temperature_base + k * temperature_step for k in range(num_samples_per_input)]\n",
    "        out = diversity_fidelity_for_one_input(\n",
    "            stroke_delta=stroke,\n",
    "            encode_fn=encode_fn,\n",
    "            decode_fn=decode_fn,\n",
    "            stroke_distance_fn=stroke_distance_fn,\n",
    "            class_id=class_id,\n",
    "            num_samples=num_samples_per_input,\n",
    "            temperatures=temps,\n",
    "            num_resample_points=num_resample_points,\n",
    "            align=align,\n",
    "            reset_on_penup=reset_on_penup,\n",
    "            rng_seed=idx,\n",
    "            decode_kwargs=decode_kwargs,\n",
    "        )\n",
    "        xs.append(out[\"fidelity\"])\n",
    "        ys.append(out[\"diversity\"])\n",
    "        per_item.append(out)\n",
    "\n",
    "    xs = np.array(xs, dtype=np.float64)\n",
    "    ys = np.array(ys, dtype=np.float64)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.scatter(xs, ys)\n",
    "    plt.xlabel(\"Fidelity\")\n",
    "    plt.ylabel(\"Diversity\")\n",
    "    plt.title(f\"Diversity vs Fidelity\")\n",
    "    plt.grid(True)\n",
    "    plt.savefig('scatter.png', dpi=600)\n",
    "    plt.show()\n",
    "\n",
    "    return {\"fidelity\": xs, \"diversity\": ys, \"details\": per_item}\n",
    "out = diversity_fidelity_for_one_input(\n",
    "    stroke_delta=stroke,\n",
    "    encode_fn=encode,\n",
    "    decode_fn=decode,\n",
    "    stroke_distance_fn=stroke_chamfer_distance_delta,\n",
    "    class_id=67,\n",
    "    num_samples=8,\n",
    "    temperatures=[0.1 + 0.05*k for k in range(8)],\n",
    ")\n",
    "\n",
    "print(\"fidelity:\", out[\"fidelity\"], \"diversity:\", out[\"diversity\"])\n",
    "strokes_list = [get_next(test_set, i, 4)[0] for i in range(30)]\n",
    "div_fid = diversity_fidelity_scatter(\n",
    "    strokes_list=strokes_list,\n",
    "    encode_fn=encode,\n",
    "    decode_fn=decode,\n",
    "    stroke_distance_fn=stroke_chamfer_distance_delta,\n",
    "    class_id=67,\n",
    "    num_samples_per_input=8,\n",
    "    temperature_base=0.1,\n",
    "    temperature_step=0.05,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def diversity_fidelity_scatter2(\n",
    "    stroke,           # list of stroke-3 delta\n",
    "    encode_fn,\n",
    "    decode_fn,\n",
    "    stroke_distance_fn,     # e.g. stroke_chamfer_distance_delta\n",
    "    class_id,\n",
    "    num_samples_per_input=8,\n",
    "    temps_in = [],\n",
    "    num_resample_points=128,\n",
    "    align=\"center\",\n",
    "    reset_on_penup=False,\n",
    "    decode_kwargs=None,\n",
    "):\n",
    "    if decode_kwargs is None:\n",
    "        decode_kwargs = {}\n",
    "\n",
    "    xs = []\n",
    "    ys = []\n",
    "    per_item = []\n",
    "\n",
    "    for temp in temps_in:\n",
    "        temps = [temp] * 8\n",
    "        out = diversity_fidelity_for_one_input(\n",
    "            stroke_delta=stroke,\n",
    "            encode_fn=encode_fn,\n",
    "            decode_fn=decode_fn,\n",
    "            stroke_distance_fn=stroke_distance_fn,\n",
    "            class_id=class_id,\n",
    "            num_samples=num_samples_per_input,\n",
    "            temperatures=temps,\n",
    "            num_resample_points=num_resample_points,\n",
    "            align=align,\n",
    "            reset_on_penup=reset_on_penup,\n",
    "            rng_seed=42,\n",
    "            decode_kwargs=decode_kwargs,\n",
    "        )\n",
    "        xs.append(out[\"fidelity\"])\n",
    "        ys.append(out[\"diversity\"])\n",
    "        per_item.append(out)\n",
    "\n",
    "    xs = np.array(xs, dtype=np.float64)\n",
    "    ys = np.array(ys, dtype=np.float64)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.scatter(xs, ys)\n",
    "    plt.xlabel(\"Fidelity\")\n",
    "    plt.ylabel(\"Diversity\")\n",
    "    plt.title(f\"Diversity vs Fidelity\")\n",
    "    plt.grid(True)\n",
    "    plt.savefig('scatter2.png', dpi=600)\n",
    "    plt.show()\n",
    "\n",
    "    return {\"fidelity\": xs, \"diversity\": ys, \"details\": per_item}\n",
    "iv_fid = diversity_fidelity_scatter2(\n",
    "    stroke=stroke,\n",
    "    encode_fn=encode,\n",
    "    decode_fn=decode,\n",
    "    stroke_distance_fn=stroke_chamfer_distance_delta,\n",
    "    class_id=67,\n",
    "    num_samples_per_input=8,\n",
    "    temps_in = [0.1 + 0.05*t for t in range(20)]\n",
    ")\n",
    "\n",
    "print(\"fidelity:\", out[\"fidelity\"], \"diversity:\", out[\"diversity\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sti = json.load(open('cls_map.json', 'r'))\n",
    "its = dict({v:k for k,v in sti.items()})\n",
    "json.dump(its, open('cls_map_i2s.json', 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4xiwp3_DFQvB"
   },
   "source": [
    "Latent Space Interpolation Example between $z_0$ and $z_1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 123
    },
    "colab_type": "code",
    "id": "WSX0uvZTFQvD",
    "outputId": "cd67af4e-5ae6-4327-876e-e1385dadbafc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get a sample drawing from the test set, and render it to .svg\n",
    "z0 = z\n",
    "_ = decode(z0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 194
    },
    "colab_type": "code",
    "id": "jQf99TxOFQvH",
    "outputId": "4265bd5f-8c66-494e-b26e-d3ac874d69bb",
    "tags": []
   },
   "outputs": [],
   "source": [
    "stroke = test_set.random_sample()\n",
    "z1 = encode(stroke)\n",
    "_ = decode(z1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tDqJR8_eFQvK"
   },
   "source": [
    "Now we interpolate between sheep $z_0$ and sheep $z_1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_YkPNL5SFQvL",
    "tags": []
   },
   "outputs": [],
   "source": [
    "z_list = [] # interpolate spherically between z0 and z1\n",
    "N = 10\n",
    "for t in np.linspace(0, 1, N):\n",
    "  z_list.append(slerp(z0, z1, t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UoM-W1tQFQvM",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for every latent vector in z_list, sample a vector image\n",
    "reconstructions = []\n",
    "for i in range(N):\n",
    "  reconstructions.append([decode(z_list[i], draw_mode=False), [0, i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "mTqmlL6GFQvQ",
    "outputId": "062e015f-29c6-4e77-c6db-e403d5cabd59",
    "tags": []
   },
   "outputs": [],
   "source": [
    "stroke_grid = make_grid_svg(reconstructions)\n",
    "draw_strokes(stroke_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vFwPna6uFQvS"
   },
   "source": [
    "Let's load the Flamingo Model, and try Unconditional (Decoder-Only) Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HH-YclgNFQvT"
   },
   "outputs": [],
   "source": [
    "model_dir = '/tmp/sketch_rnn/models/flamingo/lstm_uncond'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-Znvy3KxFQvU"
   },
   "outputs": [],
   "source": [
    "[hps_model, eval_hps_model, sample_hps_model] = load_model_compatible(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "cqDNK1cYFQvZ",
    "outputId": "d346d57c-f51a-4286-ba55-705bc27d4d0d"
   },
   "outputs": [],
   "source": [
    "# construct the sketch-rnn model here:\n",
    "reset_graph()\n",
    "model = Model(hps_model)\n",
    "eval_model = Model(eval_hps_model, reuse=True)\n",
    "sample_model = Model(sample_hps_model, reuse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7wzerSI6FQvd"
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "6mzk8KjOFQvf",
    "outputId": "c450a6c6-22ee-4a58-8451-443462b42d58"
   },
   "outputs": [],
   "source": [
    "# loads the weights from checkpoint into our model\n",
    "load_checkpoint(sess, model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X88CgcyuFQvh",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# randomly unconditionally generate 10 examples\n",
    "N = 10\n",
    "reconstructions = []\n",
    "for i in range(N):\n",
    "  reconstructions.append([decode(temperature=0.5, draw_mode=False, class_id=52), [0, i]])\n",
    "stroke_grid = make_grid_svg(reconstructions)\n",
    "draw_strokes(stroke_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 149
    },
    "colab_type": "code",
    "id": "k57REtd_FQvj",
    "outputId": "8bd69652-9d1d-475e-fc64-f205cf6b9ed1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "stroke_grid = make_grid_svg(reconstructions)\n",
    "draw_strokes(stroke_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L-rJ0iUQFQvl"
   },
   "source": [
    "Let's load the owl model, and generate two sketches using two random IID gaussian latent vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "of4SWwGdFQvm"
   },
   "outputs": [],
   "source": [
    "model_dir = '/tmp/sketch_rnn/models/owl/lstm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "jJiSZFQeFQvp",
    "outputId": "f84360ca-c2be-482f-db57-41b5ecc05768"
   },
   "outputs": [],
   "source": [
    "[hps_model, eval_hps_model, sample_hps_model] = load_model_compatible(model_dir)\n",
    "# construct the sketch-rnn model here:\n",
    "reset_graph()\n",
    "model = Model(hps_model)\n",
    "eval_model = Model(eval_hps_model, reuse=True)\n",
    "sample_model = Model(sample_hps_model, reuse=True)\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "# loads the weights from checkpoint into our model\n",
    "load_checkpoint(sess, model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "colab_type": "code",
    "id": "vR4TDoi5FQvr",
    "outputId": "db08cb2c-952c-4949-d2b0-94c11351264b"
   },
   "outputs": [],
   "source": [
    "z_0 = np.random.randn(eval_model.hps.z_size)\n",
    "_ = decode(z_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "id": "ZX23lTnpFQvt",
    "outputId": "247052f2-a0f3-4046-83d6-d08e0429fafb"
   },
   "outputs": [],
   "source": [
    "z_1 = np.random.randn(eval_model.hps.z_size)\n",
    "_ = decode(z_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7FjQsF_2FQvv"
   },
   "source": [
    "Let's interpolate between the two owls $z_0$ and $z_1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u6G37E8_FQvw"
   },
   "outputs": [],
   "source": [
    "z_list = [] # interpolate spherically between z_0 and z_1\n",
    "N = 10\n",
    "for t in np.linspace(0, 1, N):\n",
    "  z_list.append(slerp(z_0, z_1, t))\n",
    "# for every latent vector in z_list, sample a vector image\n",
    "reconstructions = []\n",
    "for i in range(N):\n",
    "  reconstructions.append([decode(z_list[i], draw_mode=False, temperature=0.1), [0, i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 149
    },
    "colab_type": "code",
    "id": "OULjMktmFQvx",
    "outputId": "94b7b68e-9c57-4a1b-b216-83770fa4be81"
   },
   "outputs": [],
   "source": [
    "stroke_grid = make_grid_svg(reconstructions)\n",
    "draw_strokes(stroke_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OiXNC-YsFQv0"
   },
   "source": [
    "Let's load the model trained on both cats and buses!  catbus!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SL7WpDDQFQv0"
   },
   "outputs": [],
   "source": [
    "model_dir = '/tmp/sketch_rnn/models/catbus/lstm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "Cvk5WOqHFQv2",
    "outputId": "8081d53d-52d6-4d18-f973-a9dd44c897f2"
   },
   "outputs": [],
   "source": [
    "[hps_model, eval_hps_model, sample_hps_model] = load_model_compatible(model_dir)\n",
    "# construct the sketch-rnn model here:\n",
    "reset_graph()\n",
    "model = Model(hps_model)\n",
    "eval_model = Model(eval_hps_model, reuse=True)\n",
    "sample_model = Model(sample_hps_model, reuse=True)\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "# loads the weights from checkpoint into our model\n",
    "load_checkpoint(sess, model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "colab_type": "code",
    "id": "icvlBPVkFQv5",
    "outputId": "f7b415fe-4d65-4b00-c0eb-fb592597dba2"
   },
   "outputs": [],
   "source": [
    "z_1 = np.random.randn(eval_model.hps.z_size)\n",
    "_ = decode(z_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "uaNxd0LuFQv-",
    "outputId": "4de5ee9a-cf14-49f4-e5f5-399a0d0b8215"
   },
   "outputs": [],
   "source": [
    "z_0 = np.random.randn(eval_model.hps.z_size)\n",
    "_ = decode(z_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VtSYkS6mFQwC"
   },
   "source": [
    "Let's interpolate between a cat and a bus!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qIDYUxBEFQwD"
   },
   "outputs": [],
   "source": [
    "z_list = [] # interpolate spherically between z_1 and z_0\n",
    "N = 10\n",
    "for t in np.linspace(0, 1, N):\n",
    "  z_list.append(slerp(z_1, z_0, t))\n",
    "# for every latent vector in z_list, sample a vector image\n",
    "reconstructions = []\n",
    "for i in range(N):\n",
    "  reconstructions.append([decode(z_list[i], draw_mode=False, temperature=0.15), [0, i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "colab_type": "code",
    "id": "ZHmnSjSaFQwH",
    "outputId": "38fe3c7e-698b-4b19-8851-e7f3ff037744"
   },
   "outputs": [],
   "source": [
    "stroke_grid = make_grid_svg(reconstructions)\n",
    "draw_strokes(stroke_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "flZ_OgzCFQwJ"
   },
   "source": [
    "Why stop here? Let's load the model trained on both elephants and pigs!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S8WwK8FPFQwK"
   },
   "outputs": [],
   "source": [
    "model_dir = '/tmp/sketch_rnn/models/elephantpig/lstm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "meOH4AFXFQwM",
    "outputId": "764938a7-bbdc-4732-e688-a8a278ab3089"
   },
   "outputs": [],
   "source": [
    "[hps_model, eval_hps_model, sample_hps_model] = load_model_compatible(model_dir)\n",
    "# construct the sketch-rnn model here:\n",
    "reset_graph()\n",
    "model = Model(hps_model)\n",
    "eval_model = Model(eval_hps_model, reuse=True)\n",
    "sample_model = Model(sample_hps_model, reuse=True)\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "# loads the weights from checkpoint into our model\n",
    "load_checkpoint(sess, model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "foZiiYPdFQwO",
    "outputId": "a09fc4fb-110f-4280-8515-c9b673cb6b90"
   },
   "outputs": [],
   "source": [
    "z_0 = np.random.randn(eval_model.hps.z_size)\n",
    "_ = decode(z_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 163
    },
    "colab_type": "code",
    "id": "6Gaz3QG1FQwS",
    "outputId": "0cfc279c-1c59-419f-86d4-ed74d5e38a26"
   },
   "outputs": [],
   "source": [
    "z_1 = np.random.randn(eval_model.hps.z_size)\n",
    "_ = decode(z_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oVtr7NnGFQwU"
   },
   "source": [
    "Tribute to an episode of [South Park](https://en.wikipedia.org/wiki/An_Elephant_Makes_Love_to_a_Pig): The interpolation between an Elephant and a Pig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lJs9JbROFQwU"
   },
   "outputs": [],
   "source": [
    "z_list = [] # interpolate spherically between z_1 and z_0\n",
    "N = 10\n",
    "for t in np.linspace(0, 1, N):\n",
    "  z_list.append(slerp(z_0, z_1, t))\n",
    "# for every latent vector in z_list, sample a vector image\n",
    "reconstructions = []\n",
    "for i in range(N):\n",
    "  reconstructions.append([decode(z_list[i], draw_mode=False, temperature=0.15), [0, i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0FOuNfJMFQwW"
   },
   "outputs": [],
   "source": [
    "stroke_grid = make_grid_svg(reconstructions, grid_space_x=25.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 130
    },
    "colab_type": "code",
    "id": "bZ6zpdiMFQwX",
    "outputId": "70679bd1-4dba-4c08-b39f-bbde81d22019"
   },
   "outputs": [],
   "source": [
    "draw_strokes(stroke_grid, factor=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KUgVRGnSFQwa"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Sketch_RNN.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "sketch",
   "language": "python",
   "name": "sketch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
